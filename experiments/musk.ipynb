{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nghia\\PycharmProjects\\ECML\\Refactor\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nghia\\anaconda2\\envs\\tf36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from load_datasets import musk\n",
    "from metrics import metrics\n",
    "from models.AE1SVM import AEOneClassSVM\n",
    "from models.DEC import DEC\n",
    "from models.RDA import RobustL21Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies ratio: 3.1372549019607843 %\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(2018)\n",
    "\n",
    "x_train, y_train, x_test, y_test = musk(random_state=1)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('Anomalies ratio:', 100*counter[-1]/(counter[1]+counter[-1]), '%')\n",
    "\n",
    "autoencoder_layers = [166, 80, 20]\n",
    "batch_size = 16\n",
    "\n",
    "data_input = tf.placeholder(tf.float32, shape=[None, 166])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 0.3307621479034424\n",
      "Test time: 0.19251537322998047\n",
      "{'AUPRC': 0.9873615510159528,\n",
      " 'AUROC': 0.8024275118004045,\n",
      " 'Confusion matrix': array([[897, 586],\n",
      "       [  0,  49]], dtype=int64),\n",
      " 'F1': 0.753781512605042,\n",
      " 'P@10': 0.9684625492772667,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.6048550236008091}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional OCSVM\n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.4, verbose=True, shrinking=True)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-Linear\n",
      "[LibSVM]Train time: 0.10411667823791504\n",
      "Test time: 0.056182861328125\n",
      "{'AUPRC': 0.9973472197524952,\n",
      " 'AUROC': 0.9585300067430884,\n",
      " 'Confusion matrix': array([[1360,  123],\n",
      "       [   0,   49]], dtype=int64),\n",
      " 'F1': 0.9567358424199789,\n",
      " 'P@10': 0.9697766097240473,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.9170600134861767}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional OCSVM\n",
    "print('OCSVM-Linear')\n",
    "libsvm = OneClassSVM(nu=0.115, verbose=True, shrinking=True, kernel='linear')\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 0.5083460807800293\n",
      "Test time: 0.14738988876342773\n",
      "{'AUPRC': 0.9996117882564627,\n",
      " 'AUROC': 0.9939312204989885,\n",
      " 'Confusion matrix': array([[1465,   18],\n",
      "       [   0,   49]], dtype=int64),\n",
      " 'F1': 0.9938941655359566,\n",
      " 'P@10': 0.9730617608409987,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.987862440997977}\n"
     ]
    }
   ],
   "source": [
    "# Train Isolation Forest\n",
    "print('IsolationForest')\n",
    "iforest = IsolationForest(contamination=0.04, verbose=1)\n",
    "t0 = time.time()\n",
    "iforest.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = iforest.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF\n",
      "Train time: 0.6838169097900391\n",
      "Test time: 0.6326839923858643\n",
      "{'AUPRC': 0.9643362970772152,\n",
      " 'AUROC': 0.4403236682400539,\n",
      " 'Confusion matrix': array([[1306,  177],\n",
      "       [  49,    0]], dtype=int64),\n",
      " 'F1': 0.9203664552501762,\n",
      " 'P@10': 0.9678055190538765,\n",
      " 'Precision': 0.9638376383763838,\n",
      " 'Recall': 0.8806473364801078}\n"
     ]
    }
   ],
   "source": [
    "# Train Local outlier factor\n",
    "print('LOF')\n",
    "lof = LocalOutlierFactor(contamination=0.1)\n",
    "t0 = time.time()\n",
    "lof.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = lof._predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1svm = AEOneClassSVM(data_input, batch_size, 'test', autoencoder_layers[1:], 0.28, 1e4, 3.0, 500,\n",
    "                       autoencoder_activation='sigmoid',\n",
    "                       full_op=tf.train.AdamOptimizer(5e-3),\n",
    "                       svm_op=tf.train.AdamOptimizer(1e-5))\n",
    "\n",
    "ae_only = AEOneClassSVM(data_input, batch_size, 'test', autoencoder_layers[1:], 0.25, 1e4, 3.0, 500,\n",
    "                        autoencoder_activation='sigmoid', ae_op=tf.train.AdamOptimizer(5e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train\n",
      "Epoch: 1 Loss: 0.35437215169270836 ( 2.5310294300902123e-05 x 10000.0 + 0.10126920213886335 ) AUROC: 0.4659244264507422\n",
      "Epoch: 2 Loss: 0.24059498107511235 ( 2.0111786822477975e-05 x 10000.0 + 0.03947711770051445 ) AUROC: 0.3690958164642375\n",
      "Epoch: 3 Loss: 0.19159184873493668 ( 1.7698292979617525e-05 x 10000.0 + 0.014608917984307981 ) AUROC: 0.36808367071524967\n",
      "Epoch: 4 Loss: 0.15702077828201594 ( 1.5207761107316983e-05 x 10000.0 + 0.004943164501314849 ) AUROC: 0.510501012145749\n",
      "Epoch: 5 Loss: 0.133790598351971 ( 1.323814534283931e-05 x 10000.0 + 0.0014091488582636017 ) AUROC: 0.4973009446693657\n",
      "Epoch: 6 Loss: 0.11680223053576899 ( 1.1658988698245654e-05 x 10000.0 + 0.00021234468307370453 ) AUROC: 0.6688174763832658\n",
      "Epoch: 7 Loss: 0.10398127736608967 ( 1.0412869354089101e-05 x 10000.0 + -0.00014741173367095148 ) AUROC: 0.5500168690958165\n",
      "Epoch: 8 Loss: 0.093745432336346 ( 9.399521000245038e-06 x 10000.0 + -0.0002497758740693136 ) AUROC: 0.6306089743589743\n",
      "Epoch: 9 Loss: 0.08539591271892871 ( 8.566722614702835e-06 x 10000.0 + -0.0002713209663341248 ) AUROC: 0.49696356275303644\n",
      "Epoch: 10 Loss: 0.07893168630163654 ( 7.920979455210803e-06 x 10000.0 + -0.0002781087471768747 ) AUROC: 0.5070428475033738\n",
      "Epoch: 11 Loss: 0.07389219695446538 ( 7.417496732052635e-06 x 10000.0 + -0.0002827729469810436 ) AUROC: 0.6946271929824561\n",
      "Epoch: 12 Loss: 0.06992360034020119 ( 7.020766706832873e-06 x 10000.0 + -0.00028406591976390166 ) AUROC: 0.6908316464237516\n",
      "Epoch: 13 Loss: 0.06677460015988818 ( 6.705990633349013e-06 x 10000.0 + -0.0002853044886994206 ) AUROC: 0.674890350877193\n",
      "Epoch: 14 Loss: 0.06400308546677135 ( 6.428178326756346e-06 x 10000.0 + -0.0002786951322181552 ) AUROC: 0.6347419028340081\n",
      "Epoch: 15 Loss: 0.0614249584721584 ( 6.17091233531634e-06 x 10000.0 + -0.00028416265070048814 ) AUROC: 0.7968539136302294\n",
      "Epoch: 16 Loss: 0.05903998480902778 ( 5.931851569733589e-06 x 10000.0 + -0.0002785320375479904 ) AUROC: 0.7796896086369771\n",
      "Epoch: 17 Loss: 0.05702725578756893 ( 5.731287296690972e-06 x 10000.0 + -0.000285620821846856 ) AUROC: 0.7893893387314439\n",
      "Epoch: 18 Loss: 0.05526124542834712 ( 5.5538319976501215e-06 x 10000.0 + -0.0002770766128901563 ) AUROC: 0.5\n",
      "Epoch: 19 Loss: 0.05364381378772212 ( 5.39271988802486e-06 x 10000.0 + -0.00028338484904345346 ) AUROC: 0.5406123481781376\n",
      "Epoch: 20 Loss: 0.05221922132703993 ( 5.250192229069916e-06 x 10000.0 + -0.00028270329135695314 ) AUROC: 0.6125590418353576\n",
      "Epoch: 21 Loss: 0.051178566926445054 ( 5.145598616864946e-06 x 10000.0 + -0.00027742226139392727 ) AUROC: 0.53125\n",
      "Epoch: 22 Loss: 0.04973232294219771 ( 5.001411925441299e-06 x 10000.0 + -0.00028179204152300465 ) AUROC: 0.6317054655870447\n",
      "Epoch: 23 Loss: 0.04924455530503217 ( 4.951607776817933e-06 x 10000.0 + -0.00027152145999708983 ) AUROC: 0.5\n",
      "Epoch: 24 Loss: 0.04671909606534671 ( 4.700126637722932e-06 x 10000.0 + -0.00028216834940941504 ) AUROC: 0.8485155195681511\n",
      "Epoch: 25 Loss: 0.047567998350056165 ( 4.783795318669743e-06 x 10000.0 + -0.00026995660432803083 ) AUROC: 0.6950067476383266\n",
      "Epoch: 26 Loss: 0.044911662581699346 ( 4.519790630130207e-06 x 10000.0 + -0.0002862421710506763 ) AUROC: 0.7683451417004049\n",
      "Epoch: 27 Loss: 0.04368875042285795 ( 4.396903225117259e-06 x 10000.0 + -0.0002802834596509248 ) AUROC: 0.5625\n",
      "Epoch: 28 Loss: 0.04252375683753319 ( 4.280402684231209e-06 x 10000.0 + -0.00028026631844589134 ) AUROC: 0.6034919028340081\n",
      "Epoch: 29 Loss: 0.04163762011559181 ( 4.1921507396729164e-06 x 10000.0 + -0.00028388839141995297 ) AUROC: 0.7284919028340081\n",
      "Epoch: 30 Loss: 0.040880689433976714 ( 4.114118995132789e-06 x 10000.0 + -0.0002605022363413393 ) AUROC: 0.5\n",
      "Epoch: 31 Loss: 0.04019062815148846 ( 4.04592274742968e-06 x 10000.0 + -0.0002685987481883928 ) AUROC: 0.5\n",
      "Epoch: 32 Loss: 0.03956093133664599 ( 3.9834017847098555e-06 x 10000.0 + -0.0002730862961875068 ) AUROC: 0.6842105263157895\n",
      "Epoch: 33 Loss: 0.03904833076826108 ( 3.932878448098313e-06 x 10000.0 + -0.0002804537614186605 ) AUROC: 0.625\n",
      "Epoch: 34 Loss: 0.038567666446461396 ( 3.884103015259979e-06 x 10000.0 + -0.0002733645291110269 ) AUROC: 0.5\n",
      "Epoch: 35 Loss: 0.03812242645064211 ( 3.84102295475458e-06 x 10000.0 + -0.0002878015337426678 ) AUROC: 0.8651737516869096\n",
      "Epoch: 36 Loss: 0.03776823056289573 ( 3.803371348314815e-06 x 10000.0 + -0.0002654838406182582 ) AUROC: 0.5\n",
      "Epoch: 37 Loss: 0.037370018553889654 ( 3.76473546174227e-06 x 10000.0 + -0.00027733608788135 ) AUROC: 0.5\n",
      "Epoch: 38 Loss: 0.03700976901584201 ( 3.728963239909777e-06 x 10000.0 + -0.00027986519476946663 ) AUROC: 0.5\n",
      "Epoch: 39 Loss: 0.0366347244362426 ( 3.6920061688018e-06 x 10000.0 + -0.00028533602462095373 ) AUROC: 0.769146423751687\n",
      "Epoch: 40 Loss: 0.03626427743949142 ( 3.654379823725987e-06 x 10000.0 + -0.000279520812377431 ) AUROC: 0.5\n",
      "Epoch: 41 Loss: 0.03588435353796467 ( 3.617195400342443e-06 x 10000.0 + -0.00028760033884858775 ) AUROC: 0.8439608636977058\n",
      "Epoch: 42 Loss: 0.0355731789582695 ( 3.583879009181378e-06 x 10000.0 + -0.0002656089714150024 ) AUROC: 0.6248313090418354\n",
      "Epoch: 43 Loss: 0.03527011248021344 ( 3.555649587141922e-06 x 10000.0 + -0.00028638311850479227 ) AUROC: 0.786268556005398\n",
      "Epoch: 44 Loss: 0.03500981050379136 ( 3.5290298922583946e-06 x 10000.0 + -0.00028048749842674904 ) AUROC: 0.5208333333333333\n",
      "Epoch: 45 Loss: 0.03477250641467525 ( 3.50470563360289e-06 x 10000.0 + -0.0002745499408323001 ) AUROC: 0.5\n",
      "Epoch: 46 Loss: 0.0345096338808147 ( 3.4789436076786e-06 x 10000.0 + -0.000279801791789485 ) AUROC: 0.5\n",
      "Epoch: 47 Loss: 0.034264658011642156 ( 3.4541868622980864e-06 x 10000.0 + -0.00027721138561473174 ) AUROC: 0.49966261808367074\n",
      "Epoch: 48 Loss: 0.03395729314268025 ( 3.424473411214897e-06 x 10000.0 + -0.0002874411593854817 ) AUROC: 0.9606528340080971\n",
      "Epoch: 49 Loss: 0.033643223880942354 ( 3.392661440800997e-06 x 10000.0 + -0.00028339075107200473 ) AUROC: 0.8090418353576248\n",
      "Epoch: 50 Loss: 0.03332786310731975 ( 3.361588137017356e-06 x 10000.0 + -0.00028801698700275295 ) AUROC: 0.9547908232118758\n",
      "Epoch: 51 Loss: 0.03302937675924862 ( 3.3317377267320174e-06 x 10000.0 + -0.00028800027432784533 ) AUROC: 0.8526062753036436\n",
      "Epoch: 52 Loss: 0.03278405432607613 ( 3.305025203944811e-06 x 10000.0 + -0.00026619878469728956 ) AUROC: 0.5\n",
      "Epoch: 53 Loss: 0.03251446493310866 ( 3.2802973721736396e-06 x 10000.0 + -0.00028850821887745575 ) AUROC: 0.9400303643724697\n",
      "Epoch: 54 Loss: 0.03228128719953151 ( 3.256818303972288e-06 x 10000.0 + -0.00028689579636442895 ) AUROC: 0.965587044534413\n",
      "Epoch: 55 Loss: 0.03206058327668632 ( 3.234293993586808e-06 x 10000.0 + -0.0002823574285881192 ) AUROC: 0.6975792847503375\n",
      "Epoch: 56 Loss: 0.03182464549744051 ( 3.2104579183985206e-06 x 10000.0 + -0.0002799330583584854 ) AUROC: 0.75\n",
      "Epoch: 57 Loss: 0.03157883687736162 ( 3.186842195348802e-06 x 10000.0 + -0.0002895864785886278 ) AUROC: 0.9258181511470984\n",
      "Epoch: 58 Loss: 0.03134813994364022 ( 3.1633835188508812e-06 x 10000.0 + -0.00028569600940529815 ) AUROC: 0.6243252361673415\n",
      "Epoch: 59 Loss: 0.031129006778492646 ( 3.140775815528982e-06 x 10000.0 + -0.00027875253577637515 ) AUROC: 0.6770833333333333\n",
      "Epoch: 60 Loss: 0.03098851870867162 ( 3.1269055005966446e-06 x 10000.0 + -0.0002805371494854198 ) AUROC: 0.65625\n",
      "Epoch: 61 Loss: 0.031122334798177085 ( 3.14107469094345e-06 x 10000.0 + -0.00028841144898358515 ) AUROC: 0.9554655870445344\n",
      "Epoch: 62 Loss: 0.031368494968788296 ( 3.1648468518374013e-06 x 10000.0 + -0.00027997476213118607 ) AUROC: 0.5833333333333333\n",
      "Epoch: 63 Loss: 0.03144651924083435 ( 3.1734582377609865e-06 x 10000.0 + -0.0002880619437086816 ) AUROC: 0.9433198380566802\n",
      "Epoch: 64 Loss: 0.03142089594423381 ( 3.1706496610555775e-06 x 10000.0 + -0.00028560064197365756 ) AUROC: 0.9700151821862347\n",
      "Epoch: 65 Loss: 0.031132961098664726 ( 3.1419147073832994e-06 x 10000.0 + -0.000286187007536296 ) AUROC: 0.9784497300944668\n",
      "Epoch: 66 Loss: 0.03057709488214231 ( 3.083342430638332e-06 x 10000.0 + -0.00025633088513916615 ) AUROC: 0.5418353576248313\n",
      "Epoch: 67 Loss: 0.030093176847969007 ( 3.037704580944348e-06 x 10000.0 + -0.00028386875694873286 ) AUROC: 0.6639676113360324\n",
      "Epoch: 68 Loss: 0.029899569742040697 ( 3.0178111046552657e-06 x 10000.0 + -0.0002785413093816221 ) AUROC: 0.65625\n",
      "Epoch: 69 Loss: 0.02998989578945185 ( 3.0252638157286675e-06 x 10000.0 + -0.0002627429229761261 ) AUROC: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 Loss: 0.030102932998557496 ( 3.03878564557998e-06 x 10000.0 + -0.00028492202556211184 ) AUROC: 0.9615384615384616\n",
      "Epoch: 71 Loss: 0.03050560296750536 ( 3.078952431678772e-06 x 10000.0 + -0.00028392066752988527 ) AUROC: 0.9935897435897436\n",
      "SVM train\n",
      "Train time: 13.401631355285645\n",
      "Test time: 0.014037132263183594\n",
      "{'AUPRC': 0.9998058941282314,\n",
      " 'AUROC': 0.9969656102494943,\n",
      " 'Confusion matrix': array([[1474,    9],\n",
      "       [   0,   49]], dtype=int64),\n",
      " 'F1': 0.9969563747040919,\n",
      " 'P@10': 0.973718791064389,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.9939312204989885}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Autoencoder-OneclassSVM\n",
    "    t0 = time.time()\n",
    "    ae1svm.fit(sess, x_train, x_train, y_train, epochs_1=71, epochs_2=0)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    out_y = ae1svm.predict(sess, x_test)\n",
    "    print('Test time:', time.time() - t0)\n",
    "\n",
    "    pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder train\n",
      "Epoch: 1 Loss: 2.4847946817578832e-05\n",
      "Epoch: 2 Loss: 1.8565625780158574e-05\n",
      "Epoch: 3 Loss: 1.549348356871823e-05\n",
      "Epoch: 4 Loss: 1.3128240757128772e-05\n",
      "Epoch: 5 Loss: 1.1289648078625499e-05\n",
      "Epoch: 6 Loss: 9.984816454984004e-06\n",
      "Epoch: 7 Loss: 9.084189176754234e-06\n",
      "Epoch: 8 Loss: 8.417192383918887e-06\n",
      "Epoch: 9 Loss: 7.894887814140007e-06\n",
      "Epoch: 10 Loss: 7.463475457983079e-06\n",
      "Epoch: 11 Loss: 7.0988474523319915e-06\n",
      "Epoch: 12 Loss: 6.785515233192569e-06\n",
      "Epoch: 13 Loss: 6.510776291096132e-06\n",
      "Epoch: 14 Loss: 6.2657520174980165e-06\n",
      "Epoch: 15 Loss: 6.049388130895453e-06\n",
      "Epoch: 16 Loss: 5.8572921974986205e-06\n",
      "Epoch: 17 Loss: 5.692568017182008e-06\n",
      "Epoch: 18 Loss: 5.558453305484423e-06\n",
      "Epoch: 19 Loss: 5.383723798920127e-06\n",
      "Epoch: 20 Loss: 5.165726749920377e-06\n",
      "Epoch: 21 Loss: 5.013275635885258e-06\n",
      "Epoch: 22 Loss: 4.883406659454302e-06\n",
      "Epoch: 23 Loss: 4.763764578824729e-06\n",
      "Epoch: 24 Loss: 4.651054155592825e-06\n",
      "Epoch: 25 Loss: 4.555836770366999e-06\n",
      "Epoch: 26 Loss: 4.679041007667585e-06\n",
      "Epoch: 27 Loss: 4.62167731979314e-06\n",
      "Epoch: 28 Loss: 4.595147104921684e-06\n",
      "Epoch: 29 Loss: 4.484736683224541e-06\n",
      "Epoch: 30 Loss: 4.314398393034935e-06\n",
      "Epoch: 31 Loss: 4.204612505299593e-06\n",
      "Epoch: 32 Loss: 4.14555934957819e-06\n",
      "Epoch: 33 Loss: 4.107964657295763e-06\n",
      "Epoch: 34 Loss: 4.066666892541e-06\n",
      "Epoch: 35 Loss: 4.013957991416937e-06\n",
      "Epoch: 36 Loss: 3.9499192163835165e-06\n",
      "Epoch: 37 Loss: 3.884951249251958e-06\n",
      "Epoch: 38 Loss: 3.827861479781811e-06\n",
      "Epoch: 39 Loss: 3.785544434209275e-06\n",
      "Epoch: 40 Loss: 3.762457982387418e-06\n",
      "Epoch: 41 Loss: 3.7434535234971765e-06\n",
      "Epoch: 42 Loss: 3.7146890475079906e-06\n",
      "Epoch: 43 Loss: 3.6896075566414916e-06\n",
      "Epoch: 44 Loss: 3.667010505701981e-06\n",
      "Epoch: 45 Loss: 3.6461345754028144e-06\n",
      "Epoch: 46 Loss: 3.6269733743145575e-06\n",
      "Epoch: 47 Loss: 3.60803374278e-06\n",
      "Epoch: 48 Loss: 3.5906682290088117e-06\n",
      "Epoch: 49 Loss: 3.5739512931482467e-06\n",
      "Epoch: 50 Loss: 3.5576790181639925e-06\n",
      "Epoch: 51 Loss: 3.541611573275398e-06\n",
      "Epoch: 52 Loss: 3.52552830199011e-06\n",
      "Epoch: 53 Loss: 3.508574274532935e-06\n",
      "Epoch: 54 Loss: 3.4874436001177706e-06\n",
      "Epoch: 55 Loss: 3.4530245352025124e-06\n",
      "Epoch: 56 Loss: 3.4032167343337553e-06\n",
      "Epoch: 57 Loss: 3.3758443725459716e-06\n",
      "Epoch: 58 Loss: 3.3702320887956742e-06\n",
      "Epoch: 59 Loss: 3.3796707083002415e-06\n",
      "Epoch: 60 Loss: 3.382487198203997e-06\n",
      "Epoch: 61 Loss: 3.371224890834366e-06\n",
      "Epoch: 62 Loss: 3.304581456129847e-06\n",
      "Epoch: 63 Loss: 3.249536335370899e-06\n",
      "Epoch: 64 Loss: 3.2285617944461848e-06\n",
      "Epoch: 65 Loss: 3.218944214917476e-06\n",
      "Epoch: 66 Loss: 3.2132601036744957e-06\n",
      "Epoch: 67 Loss: 3.207438120168019e-06\n",
      "Epoch: 68 Loss: 3.1983282027486102e-06\n",
      "Epoch: 69 Loss: 3.181364740324176e-06\n",
      "Epoch: 70 Loss: 3.1497630783740214e-06\n",
      "Epoch: 71 Loss: 3.1289735845490996e-06\n",
      "Epoch: 72 Loss: 3.1251311180443544e-06\n",
      "Epoch: 73 Loss: 3.101780791493023e-06\n",
      "Epoch: 74 Loss: 3.082093667068513e-06\n",
      "Epoch: 75 Loss: 3.0555031901481106e-06\n",
      "Epoch: 76 Loss: 3.030291740216461e-06\n",
      "Epoch: 77 Loss: 3.017531099175316e-06\n",
      "Epoch: 78 Loss: 3.040498853021977e-06\n",
      "Epoch: 79 Loss: 3.05877773249461e-06\n",
      "Epoch: 80 Loss: 3.0517669431134768e-06\n",
      "Epoch: 81 Loss: 3.030514831539073e-06\n",
      "Epoch: 82 Loss: 3.027825865870208e-06\n",
      "Epoch: 83 Loss: 3.0173813571142996e-06\n",
      "Epoch: 84 Loss: 3.0035834783822104e-06\n",
      "Epoch: 85 Loss: 2.9849281132805583e-06\n",
      "Epoch: 86 Loss: 2.9636820887818054e-06\n",
      "Epoch: 87 Loss: 2.9413288252221212e-06\n",
      "Epoch: 88 Loss: 2.917902714578934e-06\n",
      "Epoch: 89 Loss: 2.8946187371521994e-06\n",
      "Epoch: 90 Loss: 2.872047251930424e-06\n",
      "Epoch: 91 Loss: 2.851600156110876e-06\n",
      "Epoch: 92 Loss: 2.8372967457459644e-06\n",
      "Epoch: 93 Loss: 2.8141071179918215e-06\n",
      "Epoch: 94 Loss: 2.7981151528413e-06\n",
      "Epoch: 95 Loss: 2.7831835562691968e-06\n",
      "Epoch: 96 Loss: 2.7680596081065197e-06\n",
      "Epoch: 97 Loss: 2.7533048410820805e-06\n",
      "Epoch: 98 Loss: 2.7389956479953005e-06\n",
      "Epoch: 99 Loss: 2.7283648747244692e-06\n",
      "Epoch: 100 Loss: 2.7299447752097074e-06\n",
      "AE time: 11.672032117843628\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Train autoencoder for conventional methods\n",
    "    t0 = time.time()\n",
    "    ae_only.fit_ae(sess, x_train, epochs=100)\n",
    "    print('AE time:', time.time() - t0)\n",
    "\n",
    "    x_train_encoded = ae_only.encode(sess, x_train)\n",
    "    x_test_encoded = ae_only.encode(sess, x_test)\n",
    "\n",
    "    x_train_rff = ae_only.encode_rff(sess, x_train)\n",
    "    x_test_rff = ae_only.encode_rff(sess, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 0.04612135887145996\n",
      "Test time: 0.02406620979309082\n",
      "{'AUPRC': 0.993874881379745,\n",
      " 'AUROC': 0.9042481456507081,\n",
      " 'Confusion matrix': array([[1199,  284],\n",
      "       [   0,   49]], dtype=int64),\n",
      " 'F1': 0.8941088739746458,\n",
      " 'P@10': 0.9684625492772667,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.8084962913014161}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional OCSVM on bottleneck layer\n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.21, verbose=True, shrinking=True)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_encoded)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_encoded)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-Linear\n",
      "[LibSVM]Train time: 0.030548810958862305\n",
      "Test time: 0.009020328521728516\n",
      "{'AUPRC': 0.9737229631001396,\n",
      " 'AUROC': 0.5914720574676263,\n",
      " 'Confusion matrix': array([[1149,  334],\n",
      "       [  29,   20]], dtype=int64),\n",
      " 'F1': 0.8635851183765502,\n",
      " 'P@10': 0.9678055190538765,\n",
      " 'Precision': 0.9753820033955858,\n",
      " 'Recall': 0.7747808496291302}\n"
     ]
    }
   ],
   "source": [
    "print('OCSVM-Linear')\n",
    "libsvm = OneClassSVM(nu=0.21, verbose=True, shrinking=True, kernel='linear')\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_encoded)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_encoded)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-Linear on RFF\n",
      "[LibSVM]Train time: 1.280402660369873\n",
      "Test time: 0.7008624076843262\n",
      "{'AUPRC': 0.9914286758615274,\n",
      " 'AUROC': 0.8666451071325361,\n",
      " 'Confusion matrix': array([[1148,  335],\n",
      "       [   2,   47]], dtype=int64),\n",
      " 'F1': 0.8720091150778579,\n",
      " 'P@10': 0.9684625492772667,\n",
      " 'Precision': 0.9982608695652174,\n",
      " 'Recall': 0.7741065407956844}\n"
     ]
    }
   ],
   "source": [
    "print('OCSVM-Linear on RFF')\n",
    "libsvm = OneClassSVM(nu=0.25, verbose=True, shrinking=False, kernel='linear')\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_rff)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_rff)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (1530, 166)\n",
      "L shape:  (1530, 166)\n",
      "S shape:  (1530, 166)\n",
      "Out iteration:  1\n",
      "    iteration :  5 , cost :  0.022789463\n",
      "    iteration :  10 , cost :  0.01646576\n",
      "    iteration :  15 , cost :  0.011062074\n",
      "    iteration :  20 , cost :  0.008873121\n",
      "    iteration :  25 , cost :  0.007635975\n",
      "    iteration :  30 , cost :  0.0067086588\n",
      "    iteration :  35 , cost :  0.0059770215\n",
      "    iteration :  40 , cost :  0.0054218457\n",
      "    iteration :  45 , cost :  0.0049435017\n",
      "    iteration :  50 , cost :  0.0045602918\n",
      "Out iteration:  2\n",
      "    iteration :  5 , cost :  0.0032973778\n",
      "    iteration :  10 , cost :  0.003116399\n",
      "    iteration :  15 , cost :  0.0029618056\n",
      "    iteration :  20 , cost :  0.0028378225\n",
      "    iteration :  25 , cost :  0.0027382926\n",
      "    iteration :  30 , cost :  0.0026529657\n",
      "    iteration :  35 , cost :  0.0025803691\n",
      "    iteration :  40 , cost :  0.0025227075\n",
      "    iteration :  45 , cost :  0.002480416\n",
      "    iteration :  50 , cost :  0.002445822\n",
      "Out iteration:  3\n",
      "    iteration :  5 , cost :  0.0028793514\n",
      "    iteration :  10 , cost :  0.0028204778\n",
      "    iteration :  15 , cost :  0.0027416092\n",
      "    iteration :  20 , cost :  0.002648483\n",
      "    iteration :  25 , cost :  0.002602887\n",
      "    iteration :  30 , cost :  0.0025542972\n",
      "    iteration :  35 , cost :  0.0025009862\n",
      "    iteration :  40 , cost :  0.0024498058\n",
      "    iteration :  45 , cost :  0.0024067985\n",
      "    iteration :  50 , cost :  0.0023730537\n",
      "Out iteration:  4\n",
      "    iteration :  5 , cost :  0.0025789463\n",
      "    iteration :  10 , cost :  0.0025447542\n",
      "    iteration :  15 , cost :  0.002502044\n",
      "    iteration :  20 , cost :  0.002451736\n",
      "    iteration :  25 , cost :  0.0024031147\n",
      "    iteration :  30 , cost :  0.0023613127\n",
      "    iteration :  35 , cost :  0.0023247\n",
      "    iteration :  40 , cost :  0.0022909686\n",
      "    iteration :  45 , cost :  0.0022595935\n",
      "    iteration :  50 , cost :  0.0022313504\n",
      "Out iteration:  5\n",
      "    iteration :  5 , cost :  0.0022313641\n",
      "    iteration :  10 , cost :  0.0022114734\n",
      "    iteration :  15 , cost :  0.0021945967\n",
      "    iteration :  20 , cost :  0.0021806103\n",
      "    iteration :  25 , cost :  0.0021685313\n",
      "    iteration :  30 , cost :  0.002156162\n",
      "    iteration :  35 , cost :  0.0021395118\n",
      "    iteration :  40 , cost :  0.0021183481\n",
      "    iteration :  45 , cost :  0.0020981294\n",
      "    iteration :  50 , cost :  0.0020801197\n",
      "Train time: 27.5903537273407\n",
      "Test time: 0.0451204776763916\n",
      "{'AUPRC': 0.9955139976302358,\n",
      " 'AUROC': 0.9298718813216453,\n",
      " 'Confusion matrix': array([[1275,  208],\n",
      "       [   0,   49]], dtype=int64),\n",
      " 'F1': 0.924583031182016,\n",
      " 'P@10': 0.9691195795006571,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.8597437626432907}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Robust Deep Autoencoder\n",
    "    rae = RobustL21Autoencoder(sess=sess, lambda_=0.8, layers_sizes=autoencoder_layers, learning_rate=5e-3)\n",
    "    t0 = time.time()\n",
    "    L, S = rae.fit(x_train, sess=sess, inner_iteration=50, iteration=5, verbose=True, batch_size=batch_size)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    L_test, S_test = rae.predict(x_test, sess=sess)\n",
    "    print('Test time:', time.time() - t0)\n",
    "\n",
    "    s_sum = np.linalg.norm(S, axis=1)\n",
    "    s_sum_test = np.linalg.norm(S_test, axis=1)\n",
    "    out_y = [1 if s == 0 else -1 for s in s_sum_test]\n",
    "    pprint(metrics(y_test, out_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Pretraining...\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 2s 1ms/step - loss: 0.2497\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 30us/step - loss: 0.1883\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 31us/step - loss: 0.1372\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 29us/step - loss: 0.0974\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 28us/step - loss: 0.0724\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 28us/step - loss: 0.0591\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 29us/step - loss: 0.0507\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 28us/step - loss: 0.0440\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 28us/step - loss: 0.0387\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 30us/step - loss: 0.0350\n",
      "Pretraining time:  2.7543230056762695\n",
      "Update interval 10\n",
      "Save interval 478.125\n",
      "Initializing cluster centers with k-means.\n",
      "delta_label  0.00065359477124183 < tol  0.001\n",
      "Reached tolerance threshold. Stopping training.\n",
      "Train time: 9.408772706985474\n",
      "Test time: 0.07119011878967285\n",
      "{'AUPRC': 1.0,\n",
      " 'AUROC': 1.0,\n",
      " 'Confusion matrix': array([[1483,    0],\n",
      "       [   0,   49]], dtype=int64),\n",
      " 'F1': 1.0,\n",
      " 'P@10': 0.9743758212877792,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "    dec = DEC(dims=autoencoder_layers, n_clusters=5)\n",
    "    t0 = time.time()\n",
    "    dec.pretrain(x=x_train, epochs=10)\n",
    "    dec.compile(loss='kld')\n",
    "    y_pred = dec.fit(x_train, update_interval=10, batch_size=batch_size)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    scores = dec.cluster_score(x_test)\n",
    "    threshold = np.partition(scores.flatten(), int(counter[-1]))[int(counter[-1])]\n",
    "    print('Test time:', time.time() - t0)\n",
    "    out_y = [1 if s > 2*threshold else -1 for s in scores]\n",
    "    pprint(metrics(y_test, out_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
