{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nghia\\PycharmProjects\\ECML\\Refactor\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nghia\\anaconda2\\envs\\tf36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from load_datasets import kddcup\n",
    "from metrics import metrics\n",
    "from models.AE1SVM import AEOneClassSVM\n",
    "from models.DEC import DEC\n",
    "from models.RDA import RobustL21Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies ratio: 4.998242118832767 %\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(2018)\n",
    "\n",
    "x_train, y_train, x_test, y_test = kddcup(random_state=3, percent10=True)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('Anomalies ratio:', 100*counter[-1]/(counter[1]+counter[-1]), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 62.47549605369568\n",
      "Test time: 18.70576310157776\n",
      "{'AUPRC': 0.9897978499698971,\n",
      " 'AUROC': 0.9016033221154834,\n",
      " 'Confusion matrix': array([[47237,  1402],\n",
      "       [  430,  2130]], dtype=int64),\n",
      " 'F1': 0.9809773015180778,\n",
      " 'P@10': 0.9501455390806619,\n",
      " 'Precision': 0.9909790840623492,\n",
      " 'Recall': 0.9711753942309669}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional RBF-OCSVM on raw input\n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.05, verbose=True, shrinking=False)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 66.01519727706909\n",
      "Test time: 18.03073811531067\n",
      "{'AUPRC': 0.9583174383815292,\n",
      " 'AUROC': 0.5867697435121507,\n",
      " 'Confusion matrix': array([[46725,  1914],\n",
      "       [ 2015,   545]], dtype=int64),\n",
      " 'F1': 0.9596524918103492,\n",
      " 'P@10': 0.950008790951181,\n",
      " 'Precision': 0.9586581862946245,\n",
      " 'Recall': 0.9606488620243014}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional Linear-OCSVM\n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.05, verbose=True, shrinking=False, kernel='linear')\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 18.21442174911499\n",
      "Test time: 5.948817253112793\n",
      "{'AUPRC': 0.9956962072271266,\n",
      " 'AUROC': 0.9572772066590083,\n",
      " 'Confusion matrix': array([[45072,  3567],\n",
      "       [   31,  2529]], dtype=int64),\n",
      " 'F1': 0.961618058074289,\n",
      " 'P@10': 0.9500478618453183,\n",
      " 'Precision': 0.9993126843003791,\n",
      " 'Recall': 0.9266637883180164}\n"
     ]
    }
   ],
   "source": [
    "# Train Isolation Forest\n",
    "print('IsolationForest')\n",
    "iforest = IsolationForest(contamination=0.12, verbose=1)\n",
    "t0 = time.time()\n",
    "iforest.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = iforest.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_layers = [118, 80, 40, 20]\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Pretraining...\n",
      "Epoch 1/1\n",
      "51198/51198 [==============================] - 2s 33us/step - loss: 0.0131\n",
      "Pretraining time:  2.312150001525879\n",
      "Update interval 10\n",
      "Save interval 1999.921875\n",
      "Initializing cluster centers with k-means.\n",
      "delta_label  0.00011719207781553967 < tol  0.001\n",
      "Reached tolerance threshold. Stopping training.\n",
      "Train time: 10.319435834884644\n",
      "Test time: 1.9491820335388184\n",
      "{'AUPRC': 0.994932380796463,\n",
      " 'AUROC': 0.9496290190870496,\n",
      " 'Confusion matrix': array([[44309,  4330],\n",
      "       [   30,  2530]], dtype=int64),\n",
      " 'F1': 0.9531071866463035,\n",
      " 'P@10': 0.950067397292387,\n",
      " 'Precision': 0.999323394754054,\n",
      " 'Recall': 0.910976788174099}\n"
     ]
    }
   ],
   "source": [
    "dec = DEC(dims=autoencoder_layers, n_clusters=5)\n",
    "t0 = time.time()\n",
    "dec.pretrain(x=x_train, epochs=1)\n",
    "dec.compile(loss='kld')\n",
    "y_pred = dec.fit(x_train, update_interval=10, batch_size=batch_size)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "scores = dec.cluster_score(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "threshold = np.partition(scores.flatten(), int(counter[-1]))[int(counter[-1])]\n",
    "out_y = [1 if s > 2*threshold else -1 for s in scores]\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (51198, 118)\n",
      "L shape:  (51198, 118)\n",
      "S shape:  (51198, 118)\n",
      "Out iteration:  1\n",
      "    iteration :  5 , cost :  0.018701918\n",
      "    iteration :  10 , cost :  0.018692752\n",
      "    iteration :  15 , cost :  0.018691037\n",
      "    iteration :  20 , cost :  0.011147634\n",
      "Out iteration:  2\n",
      "    iteration :  5 , cost :  0.0019389873\n",
      "    iteration :  10 , cost :  0.0015561715\n",
      "    iteration :  15 , cost :  0.0012655357\n",
      "    iteration :  20 , cost :  0.0011443329\n",
      "Out iteration:  3\n",
      "    iteration :  5 , cost :  0.0012811279\n",
      "    iteration :  10 , cost :  0.0011820417\n",
      "    iteration :  15 , cost :  0.0011152904\n",
      "    iteration :  20 , cost :  0.0010681031\n",
      "Out iteration:  4\n",
      "    iteration :  5 , cost :  0.0011503145\n",
      "    iteration :  10 , cost :  0.0010669037\n",
      "    iteration :  15 , cost :  0.0009611702\n",
      "    iteration :  20 , cost :  0.0008440685\n",
      "Out iteration:  5\n",
      "    iteration :  5 , cost :  0.0008549378\n",
      "    iteration :  10 , cost :  0.0008220407\n",
      "    iteration :  15 , cost :  0.00078954484\n",
      "    iteration :  20 , cost :  0.00079035707\n",
      "Train time: 129.05813241004944\n",
      "Test time: 0.58455491065979\n",
      "{'AUPRC': 0.9627194210041504,\n",
      " 'AUROC': 0.6320927281219804,\n",
      " 'Confusion matrix': array([[47695,   944],\n",
      "       [ 1834,   726]], dtype=int64),\n",
      " 'F1': 0.9717015728139518,\n",
      " 'P@10': 0.9501064681865244,\n",
      " 'Precision': 0.9629711885965798,\n",
      " 'Recall': 0.9805917062439606}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Robust Deep Autoencoder\n",
    "    rae = RobustL21Autoencoder(sess=sess, lambda_=1, layers_sizes=autoencoder_layers, learning_rate=1e-3)\n",
    "    t0 = time.time()\n",
    "    L, S = rae.fit(x_train, sess=sess, inner_iteration=20, iteration=5, verbose=True, batch_size=batch_size)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    L_test, S_test = rae.predict(x_test, sess=sess)\n",
    "    print('Test time:', time.time() - t0)\n",
    "\n",
    "    s_sum = np.linalg.norm(S, axis=1)\n",
    "    s_sum_test = np.linalg.norm(S_test, axis=1)\n",
    "    out_y = [1 if s == 0 else -1 for s in s_sum_test]\n",
    "    pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = tf.placeholder(tf.float32, shape=[None, 118], name='data_input')\n",
    "ae1svm = AEOneClassSVM(data_input, batch_size, 'test', autoencoder_layers[1:], 0.3, 1e4, 3.0, 400,\n",
    "                       autoencoder_activation='sigmoid',\n",
    "                       full_op=tf.train.AdamOptimizer(1e-3),\n",
    "                       svm_op=tf.train.AdamOptimizer(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train\n",
      "Epoch: 1 Loss: 0.005133832961843603 ( 2.0757060618930331e-07 x 10000.0 + 0.0030581268175835117 ) AUROC: 0.5938248382399152\n",
      "Epoch: 2 Loss: 0.0023592526411897498 ( 9.218054321916911e-08 x 10000.0 + 0.0014374471929903267 ) AUROC: 0.47143266682762475\n",
      "Epoch: 3 Loss: 0.00111183113751735 ( 4.779282124767853e-08 x 10000.0 + 0.0006339029481790136 ) AUROC: 0.47414711687780303\n",
      "Epoch: 4 Loss: 0.000636158699570021 ( 3.826987147337059e-08 x 10000.0 + 0.000253459988983773 ) AUROC: 0.5256240758559357\n",
      "Epoch: 5 Loss: 0.00040789565852277095 ( 3.208330369252605e-08 x 10000.0 + 8.706260628102137e-05 ) AUROC: 0.5983669987083585\n",
      "Epoch: 6 Loss: 0.00031276110387546037 ( 2.9071924136254864e-08 x 10000.0 + 2.2041857710592103e-05 ) AUROC: 0.597761574151571\n",
      "Epoch: 7 Loss: 0.0002683487863874821 ( 2.683467986637356e-08 x 10000.0 + 1.9971919561988733e-09 ) AUROC: 0.9386815567580732\n",
      "Epoch: 8 Loss: 0.00012692300000830207 ( 1.3301545365742023e-08 x 10000.0 + -6.092454340361148e-06 ) AUROC: 0.9533265233465\n",
      "Epoch: 9 Loss: 0.0001097576353409229 ( 1.1724592757149829e-08 x 10000.0 + -7.488297724137991e-06 ) AUROC: 0.9613961070756303\n",
      "Epoch: 10 Loss: 0.00010059410633763846 ( 1.0833174684475868e-08 x 10000.0 + -7.737634740698555e-06 ) AUROC: 0.9675023181408249\n",
      "SVM train\n",
      "Train time: 30.054906845092773\n",
      "Test time: 0.4782724380493164\n",
      "{'AUPRC': 0.9965869646368197,\n",
      " 'AUROC': 0.9663337853240197,\n",
      " 'Confusion matrix': array([[46238,  2401],\n",
      "       [   46,  2514]], dtype=int64),\n",
      " 'F1': 0.9742212108761839,\n",
      " 'P@10': 0.9501064681865244,\n",
      " 'Precision': 0.9990061360297295,\n",
      " 'Recall': 0.9506363206480396}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Autoencoder-OneclassSVM\n",
    "    t0 = time.time()\n",
    "    ae1svm.fit(sess, x_train, x_train, y_train, epochs_1=10, epochs_2=0)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    out_y = ae1svm.predict(sess, x_test)\n",
    "    print('Test time:', time.time() - t0)\n",
    "\n",
    "    pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder train\n",
      "Epoch: 1 Loss: 2.3752314658983457e-07\n",
      "Epoch: 2 Loss: 1.0828961513066572e-07\n",
      "Epoch: 3 Loss: 6.899528518709718e-08\n",
      "Epoch: 4 Loss: 4.367205356212979e-08\n",
      "Epoch: 5 Loss: 3.686946095630472e-08\n",
      "Epoch: 6 Loss: 3.163596261788208e-08\n",
      "Epoch: 7 Loss: 2.9726613091325343e-08\n",
      "Epoch: 8 Loss: 2.8324936053413792e-08\n",
      "Epoch: 9 Loss: 2.6877216321419e-08\n",
      "Epoch: 10 Loss: 2.545191423577547e-08\n",
      "Epoch: 11 Loss: 1.6543619306538666e-08\n",
      "Epoch: 12 Loss: 1.5866660503779354e-08\n",
      "Epoch: 13 Loss: 1.5412354701396878e-08\n",
      "Epoch: 14 Loss: 1.505210683086784e-08\n",
      "Epoch: 15 Loss: 8.93159368299866e-09\n",
      "Epoch: 16 Loss: 7.769486907747482e-09\n",
      "Epoch: 17 Loss: 7.503624968411175e-09\n",
      "Epoch: 18 Loss: 7.317159902072299e-09\n",
      "Epoch: 19 Loss: 7.170258832294972e-09\n",
      "Epoch: 20 Loss: 7.052394515119895e-09\n",
      "AE time: 28.71333956718445\n"
     ]
    }
   ],
   "source": [
    "ae_only = AEOneClassSVM(data_input, batch_size, 'test_ae', autoencoder_layers[1:], 0.3, 1e4, 3.0, 400,\n",
    "                        autoencoder_activation='sigmoid', ae_op=tf.train.AdamOptimizer(1e-3))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Train autoencoder for conventional methods\n",
    "    t0 = time.time()\n",
    "    ae_only.fit_ae(sess, x_train, epochs=20)\n",
    "    print('AE time:', time.time() - t0)\n",
    "\n",
    "    x_train_encoded = ae_only.encode(sess, x_train)\n",
    "    x_test_encoded = ae_only.encode(sess, x_test)\n",
    "\n",
    "    x_train_rff = ae_only.encode_rff(sess, x_train)\n",
    "    x_test_rff = ae_only.encode_rff(sess, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 56.95638394355774\n",
      "Test time: 11.061755895614624\n",
      "{'AUPRC': 0.9951433364355408,\n",
      " 'AUROC': 0.9518083683168342,\n",
      " 'Confusion matrix': array([[44654,  3985],\n",
      "       [   37,  2523]], dtype=int64),\n",
      " 'F1': 0.9569056037715633,\n",
      " 'P@10': 0.950008790951181,\n",
      " 'Precision': 0.9991720928151082,\n",
      " 'Recall': 0.9180698616336684}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional OCSVM on bottleneck layer\n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.13, verbose=True, shrinking=True)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_encoded)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_encoded)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 29.205822706222534\n",
      "Test time: 5.433445930480957\n",
      "{'AUPRC': 0.9844829829510572,\n",
      " 'AUROC': 0.8488579003281831,\n",
      " 'Confusion matrix': array([[43607,  5032],\n",
      "       [  509,  2051]], dtype=int64),\n",
      " 'F1': 0.9402619804862271,\n",
      " 'P@10': 0.9500283263982496,\n",
      " 'Precision': 0.9884622359234745,\n",
      " 'Recall': 0.8965439256563663}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional OCSVM-Linear on bottleneck layer\n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.14, verbose=True, shrinking=True, kernel='linear')\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_encoded)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_encoded)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-Linear on RFF\n",
      "[LibSVM]Train time: 920.3023386001587\n",
      "Test time: 323.52916526794434\n",
      "{'AUPRC': 0.9910012569558307,\n",
      " 'AUROC': 0.9121187633637616,\n",
      " 'Confusion matrix': array([[44422,  4217],\n",
      "       [  228,  2332]], dtype=int64),\n",
      " 'F1': 0.9523523673745029,\n",
      " 'P@10': 0.9500478618453183,\n",
      " 'Precision': 0.9948936170212765,\n",
      " 'Recall': 0.9133000267275232}\n"
     ]
    }
   ],
   "source": [
    "print('OCSVM-Linear on RFF')\n",
    "libsvm = OneClassSVM(nu=0.13, verbose=True, shrinking=False, kernel='linear', tol=0.1)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_rff)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_rff)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = kddcup(random_state=3, percent10=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_layers = [113, 80, 40, 20]\n",
    "batch_size = 1024\n",
    "data_input = tf.placeholder(tf.float32, shape=[None, 113], name='data_input_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1svm = AEOneClassSVM(data_input, batch_size, 'testfull', autoencoder_layers[1:], 0.25, 1e5, 3.0, 400,\n",
    "                       autoencoder_activation='sigmoid',\n",
    "                       full_op=tf.train.AdamOptimizer(5e-3),\n",
    "                       svm_op=tf.train.AdamOptimizer(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train\n",
      "Epoch: 1 Loss: 0.0004017893567186624 ( 3.99424684781271e-09 x 100000.0 + 2.364681148951696e-06 ) AUROC: 0.9072939582793937\n",
      "Epoch: 2 Loss: 0.00027372131719001166 ( 2.745042451598744e-09 x 100000.0 + -7.829387312352536e-07 ) AUROC: 0.9490486052016421\n",
      "Epoch: 3 Loss: 0.00023601988392443185 ( 2.367943749345879e-09 x 100000.0 + -7.74488252508887e-07 ) AUROC: 0.6270106519548841\n",
      "Epoch: 4 Loss: 0.00016080325610709533 ( 1.6159207660144933e-09 x 100000.0 + -7.888224880092238e-07 ) AUROC: 0.6307371892011053\n",
      "Epoch: 5 Loss: 8.719775410032689e-05 ( 8.799845884620085e-10 x 100000.0 + -8.006993178929529e-07 ) AUROC: 0.9706068972420496\n",
      "SVM train\n",
      "Train time: 143.3942165374756\n",
      "Test time: 4.308180809020996\n",
      "{'AUPRC': 0.9970054674308171,\n",
      " 'AUROC': 0.9701269396528461,\n",
      " 'Confusion matrix': array([[458661,  27730],\n",
      "       [    70,  25530]], dtype=int64),\n",
      " 'F1': 0.9705858079697648,\n",
      " 'P@10': 0.9500098636472838,\n",
      " 'Precision': 0.999847405124136,\n",
      " 'Recall': 0.9429882543056923}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Autoencoder-OneclassSVM\n",
    "    t0 = time.time()\n",
    "    ae1svm.fit(sess, x_train, x_train, y_train, epochs_1=5, epochs_2=0)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    out_y = ae1svm.predict(sess, x_test)\n",
    "    print('Test time:', time.time() - t0)\n",
    "\n",
    "    pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
