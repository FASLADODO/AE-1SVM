{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nghia\\PycharmProjects\\ECML\\Refactor\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nghia\\anaconda2\\envs\\tf36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from load_datasets import usps\n",
    "from metrics import metrics\n",
    "from models.AE1SVM import AEOneClassSVM\n",
    "from models.DEC import DEC\n",
    "from models.RDA import RobustL21Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies ratio: 5.0 %\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(2018)\n",
    "\n",
    "x_train, y_train, x_test, y_test = usps(random_state=3)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('Anomalies ratio:', 100*counter[-1]/(counter[1]+counter[-1]), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_layers = [256, 128, 64, 32]\n",
    "batch_size = 16\n",
    "\n",
    "data_input = tf.placeholder(tf.float32, shape=[None, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 0.021056652069091797\n",
      "Test time: 0.015059471130371094\n",
      "{'AUPRC': 0.9974736842105263,\n",
      " 'AUROC': 0.9747368421052631,\n",
      " 'Confusion matrix': array([[451,  24],\n",
      "       [  0,  25]], dtype=int64),\n",
      " 'F1': 0.9740820734341253,\n",
      " 'P@10': 0.9612244897959183,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.9494736842105264}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional OCSVM\n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.11, verbose=True, shrinking=True, gamma=0.04)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 0.03509020805358887\n",
      "Test time: 0.018445730209350586\n",
      "{'AUPRC': 0.9755563207083128,\n",
      " 'AUROC': 0.7610526315789473,\n",
      " 'Confusion matrix': array([[419,  56],\n",
      "       [  9,  16]], dtype=int64),\n",
      " 'F1': 0.9280177187153932,\n",
      " 'P@10': 0.9551020408163265,\n",
      " 'Precision': 0.9789719626168224,\n",
      " 'Recall': 0.8821052631578947}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional OCSVM\n",
    "print('OCSVM-Linear')\n",
    "libsvm = OneClassSVM(nu=0.15, verbose=True, shrinking=True, kernel='linear')\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest\n",
      "Train time: 0.25407886505126953\n",
      "Test time: 0.059157609939575195\n",
      "{'AUPRC': 0.9986315789473684,\n",
      " 'AUROC': 0.9863157894736843,\n",
      " 'Confusion matrix': array([[462,  13],\n",
      "       [  0,  25]], dtype=int64),\n",
      " 'F1': 0.9861259338313767,\n",
      " 'P@10': 0.963265306122449,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.9726315789473684}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Train Isolation Forest\n",
    "print('IsolationForest')\n",
    "iforest = IsolationForest(contamination=0.08, verbose=1)\n",
    "t0 = time.time()\n",
    "iforest.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = iforest.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (500, 256)\n",
      "L shape:  (500, 256)\n",
      "S shape:  (500, 256)\n",
      "Out iteration:  1\n",
      "    iteration :  5 , cost :  0.007713088\n",
      "Out iteration:  2\n",
      "    iteration :  5 , cost :  0.0051952614\n",
      "Out iteration:  3\n",
      "    iteration :  5 , cost :  0.0051321657\n",
      "Out iteration:  4\n",
      "    iteration :  5 , cost :  0.005561769\n",
      "Out iteration:  5\n",
      "    iteration :  5 , cost :  0.0056907134\n",
      "Train time: 1.6166083812713623\n",
      "Test time: 0.015040874481201172\n",
      "{'AUPRC': 0.998,\n",
      " 'AUROC': 0.98,\n",
      " 'Confusion matrix': array([[456,  19],\n",
      "       [  0,  25]], dtype=int64),\n",
      " 'F1': 0.9795918367346939,\n",
      " 'P@10': 0.9530612244897959,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.96}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Robust Deep Autoencoder\n",
    "    rae = RobustL21Autoencoder(sess=sess, lambda_=1.7, layers_sizes=autoencoder_layers, learning_rate=1e-2)\n",
    "    t0 = time.time()\n",
    "    L, S = rae.fit(x_train, sess=sess, inner_iteration=5, iteration=5, verbose=True, batch_size=batch_size)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    L_test, S_test = rae.predict(x_test, sess=sess)\n",
    "    print('Test time:', time.time() - t0)\n",
    "\n",
    "    s_sum = np.linalg.norm(S, axis=1)\n",
    "    s_sum_test = np.linalg.norm(S_test, axis=1)\n",
    "    out_y = [1 if s == 0 else -1 for s in s_sum_test]\n",
    "    pprint(metrics(y_test, out_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Pretraining...\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0944\n",
      "Pretraining time:  1.5691707134246826\n",
      "Update interval 10\n",
      "Save interval 156.25\n",
      "Initializing cluster centers with k-means.\n",
      "delta_label  0.0 < tol  0.001\n",
      "Reached tolerance threshold. Stopping training.\n",
      "Train time: 4.227656841278076\n",
      "Test time: 0.02710247039794922\n",
      "{'AUPRC': 0.9924399763453579,\n",
      " 'AUROC': 0.9263157894736843,\n",
      " 'Confusion matrix': array([[443,  32],\n",
      "       [  2,  23]], dtype=int64),\n",
      " 'F1': 0.9630434782608697,\n",
      " 'P@10': 0.9571428571428572,\n",
      " 'Precision': 0.9955056179775281,\n",
      " 'Recall': 0.9326315789473684}\n"
     ]
    }
   ],
   "source": [
    "dec = DEC(dims=autoencoder_layers, n_clusters=5)\n",
    "t0 = time.time()\n",
    "dec.pretrain(x=x_train, epochs=1)\n",
    "dec.compile(loss='kld')\n",
    "y_pred = dec.fit(x_train, update_interval=10, batch_size=batch_size)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "scores = dec.cluster_score(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "threshold = np.partition(scores.flatten(), int(counter[-1]))[int(counter[-1])]\n",
    "out_y = [1 if s > threshold else -1 for s in scores]\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1svm = AEOneClassSVM(data_input, batch_size, 'test', autoencoder_layers[1:], 0.28, 1e3, 3.0, 500,\n",
    "                       autoencoder_activation='sigmoid',\n",
    "                       full_op=tf.train.AdamOptimizer(5e-3),\n",
    "                       svm_op=tf.train.AdamOptimizer(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train\n",
      "Epoch: 1 Loss: 0.6347761840820313 ( 5.934059247374535e-05 x 1000.0 + 0.5754356079101562 ) AUROC: 0.5\n",
      "Epoch: 2 Loss: 0.46069891357421877 ( 3.311109915375709e-05 x 1000.0 + 0.42758782958984376 ) AUROC: 0.5\n",
      "Epoch: 3 Loss: 0.3463565673828125 ( 2.874456159770489e-05 x 1000.0 + 0.31761199951171876 ) AUROC: 0.49894736842105264\n",
      "Epoch: 4 Loss: 0.2627142333984375 ( 2.7297617867588998e-05 x 1000.0 + 0.23541661071777345 ) AUROC: 0.43473684210526314\n",
      "Epoch: 5 Loss: 0.19983882141113282 ( 2.598492056131363e-05 x 1000.0 + 0.17385389709472657 ) AUROC: 0.5\n",
      "Epoch: 6 Loss: 0.14975242614746093 ( 2.2064670920372008e-05 x 1000.0 + 0.12768775939941407 ) AUROC: 0.45473684210526316\n",
      "Epoch: 7 Loss: 0.1108739013671875 ( 1.7661822959780694e-05 x 1000.0 + 0.09321207427978516 ) AUROC: 0.49894736842105264\n",
      "Epoch: 8 Loss: 0.08266778564453126 ( 1.50770153850317e-05 x 1000.0 + 0.06759077453613281 ) AUROC: 0.9336842105263157\n",
      "Epoch: 9 Loss: 0.061742645263671875 ( 1.3086799532175063e-05 x 1000.0 + 0.04865584564208984 ) AUROC: 0.8252631578947368\n",
      "Epoch: 10 Loss: 0.04644728469848633 ( 1.1772449128329754e-05 x 1000.0 + 0.03467483520507812 ) AUROC: 0.6568421052631579\n",
      "Epoch: 11 Loss: 0.03511636734008789 ( 1.0690723545849323e-05 x 1000.0 + 0.024425643920898438 ) AUROC: 0.6789473684210525\n",
      "Epoch: 12 Loss: 0.026806964874267578 ( 9.817982092499732e-06 x 1000.0 + 0.016988983154296877 ) AUROC: 0.8305263157894737\n",
      "Epoch: 13 Loss: 0.02115672492980957 ( 9.503294713795184e-06 x 1000.0 + 0.011653429985046386 ) AUROC: 0.5789473684210527\n",
      "Epoch: 14 Loss: 0.016728048324584962 ( 8.922357112169267e-06 x 1000.0 + 0.007805691242218017 ) AUROC: 0.8852631578947369\n",
      "Epoch: 15 Loss: 0.013502326011657715 ( 8.349455893039703e-06 x 1000.0 + 0.005152870178222657 ) AUROC: 0.64\n",
      "Epoch: 16 Loss: 0.010965099334716797 ( 7.754150778055191e-06 x 1000.0 + 0.0032109482288360594 ) AUROC: 0.9221052631578949\n",
      "Epoch: 17 Loss: 0.008763986587524414 ( 6.881413981318474e-06 x 1000.0 + 0.0018825724124908448 ) AUROC: 0.9210526315789473\n",
      "Epoch: 18 Loss: 0.007812808513641358 ( 6.841945927590132e-06 x 1000.0 + 0.0009708623290061951 ) AUROC: 0.8726315789473684\n",
      "Epoch: 19 Loss: 0.006496585369110107 ( 6.150906439870596e-06 x 1000.0 + 0.0003456789255142212 ) AUROC: 0.9347368421052631\n",
      "Epoch: 20 Loss: 0.005743350982666016 ( 5.812547635287047e-06 x 1000.0 + -6.919683516025543e-05 ) AUROC: 0.9294736842105263\n",
      "Epoch: 21 Loss: 0.00498969554901123 ( 5.344743840396404e-06 x 1000.0 + -0.0003550482988357544 ) AUROC: 0.9431578947368421\n",
      "Epoch: 22 Loss: 0.004632796287536621 ( 5.139502696692943e-06 x 1000.0 + -0.0005067064762115478 ) AUROC: 0.6557894736842105\n",
      "Epoch: 23 Loss: 0.004359049320220947 ( 5.017582792788744e-06 x 1000.0 + -0.0006585335731506348 ) AUROC: 0.9442105263157895\n",
      "Epoch: 24 Loss: 0.003927072286605835 ( 4.6662446111440655e-06 x 1000.0 + -0.0007391722202301026 ) AUROC: 0.9294736842105263\n",
      "Epoch: 25 Loss: 0.004366398334503174 ( 5.1531107164919374e-06 x 1000.0 + -0.0007867121696472168 ) AUROC: 0.911578947368421\n",
      "Epoch: 26 Loss: 0.0037667734622955323 ( 4.589438438415528e-06 x 1000.0 + -0.0008226650357246399 ) AUROC: 0.9231578947368422\n",
      "Epoch: 27 Loss: 0.0035176236629486084 ( 4.360936582088471e-06 x 1000.0 + -0.0008433130383491516 ) AUROC: 0.9189473684210526\n",
      "Epoch: 28 Loss: 0.0035317964553833008 ( 4.383440595120192e-06 x 1000.0 + -0.0008516439199447632 ) AUROC: 0.9221052631578949\n",
      "Epoch: 29 Loss: 0.0033864006996154783 ( 4.247084259986877e-06 x 1000.0 + -0.0008606834411621093 ) AUROC: 0.8926315789473684\n",
      "Epoch: 30 Loss: 0.003161242961883545 ( 4.028972238302231e-06 x 1000.0 + -0.0008677290678024292 ) AUROC: 0.9052631578947368\n",
      "Epoch: 31 Loss: 0.003168048858642578 ( 4.028099123388529e-06 x 1000.0 + -0.0008600502610206604 ) AUROC: 0.7989473684210526\n",
      "Epoch: 32 Loss: 0.0028060615062713624 ( 3.6842240951955317e-06 x 1000.0 + -0.0008781625628471374 ) AUROC: 0.9484210526315789\n",
      "Epoch: 33 Loss: 0.002771839141845703 ( 3.654351457953453e-06 x 1000.0 + -0.0008825123906135559 ) AUROC: 0.9094736842105262\n",
      "Epoch: 34 Loss: 0.0028879485130310057 ( 3.767843823879957e-06 x 1000.0 + -0.000879895269870758 ) AUROC: 0.9136842105263158\n",
      "Epoch: 35 Loss: 0.0027740592956542968 ( 3.61119513399899e-06 x 1000.0 + -0.0008371357917785645 ) AUROC: 0.7357894736842105\n",
      "Epoch: 36 Loss: 0.0024998989105224608 ( 3.3650475088506938e-06 x 1000.0 + -0.0008651485443115234 ) AUROC: 0.9273684210526316\n",
      "Epoch: 37 Loss: 0.0023351621627807615 ( 3.2179041299968957e-06 x 1000.0 + -0.0008827418684959411 ) AUROC: 0.96\n",
      "Epoch: 38 Loss: 0.0021930153369903566 ( 3.07825137861073e-06 x 1000.0 + -0.0008852360248565674 ) AUROC: 0.9536842105263158\n",
      "Epoch: 39 Loss: 0.002193688631057739 ( 3.0653837602585554e-06 x 1000.0 + -0.0008716950416564941 ) AUROC: 0.8452631578947368\n",
      "Epoch: 40 Loss: 0.002115156412124634 ( 2.995049813762307e-06 x 1000.0 + -0.0008798933029174805 ) AUROC: 0.9031578947368422\n",
      "Epoch: 41 Loss: 0.002055392742156982 ( 2.8806149493902924e-06 x 1000.0 + -0.0008252221345901489 ) AUROC: 0.7578947368421053\n",
      "Epoch: 42 Loss: 0.002158236742019653 ( 3.0100669246166943e-06 x 1000.0 + -0.0008518303036689759 ) AUROC: 0.7947368421052631\n",
      "Epoch: 43 Loss: 0.002100189208984375 ( 2.9818490147590636e-06 x 1000.0 + -0.000881659746170044 ) AUROC: 0.9557894736842105\n",
      "Epoch: 44 Loss: 0.002089559555053711 ( 2.9740175232291224e-06 x 1000.0 + -0.0008844581246376038 ) AUROC: 0.9494736842105262\n",
      "Epoch: 45 Loss: 0.0019568374156951904 ( 2.8418239671736954e-06 x 1000.0 + -0.0008849865794181824 ) AUROC: 0.9136842105263158\n",
      "Epoch: 46 Loss: 0.0018914597034454346 ( 2.7494546957314013e-06 x 1000.0 + -0.0008579950332641602 ) AUROC: 0.7305263157894737\n",
      "Epoch: 47 Loss: 0.0019603980779647825 ( 2.8421594761312008e-06 x 1000.0 + -0.0008817614316940308 ) AUROC: 0.8978947368421053\n",
      "Epoch: 48 Loss: 0.001956177234649658 ( 2.838927321135998e-06 x 1000.0 + -0.0008827500343322754 ) AUROC: 0.9052631578947368\n",
      "Epoch: 49 Loss: 0.0018310434818267823 ( 2.670171204954386e-06 x 1000.0 + -0.0008391278386116027 ) AUROC: 0.6442105263157895\n",
      "Epoch: 50 Loss: 0.0019531582593917845 ( 2.8363780584186315e-06 x 1000.0 + -0.000883219838142395 ) AUROC: 0.8905263157894736\n",
      "Epoch: 51 Loss: 0.0019170688390731812 ( 2.7963165193796157e-06 x 1000.0 + -0.000879247784614563 ) AUROC: 0.8736842105263158\n",
      "Epoch: 52 Loss: 0.001870595932006836 ( 2.717936644330621e-06 x 1000.0 + -0.0008473408818244934 ) AUROC: 0.8178947368421052\n",
      "Epoch: 53 Loss: 0.00195558762550354 ( 2.774541964754462e-06 x 1000.0 + -0.0008189541697502137 ) AUROC: 0.6578947368421053\n",
      "Epoch: 54 Loss: 0.001656840205192566 ( 2.5430107489228247e-06 x 1000.0 + -0.000886170506477356 ) AUROC: 0.9505263157894737\n",
      "Epoch: 55 Loss: 0.0016735773086547852 ( 2.5508091785013675e-06 x 1000.0 + -0.0008772317767143249 ) AUROC: 0.8694736842105264\n",
      "Epoch: 56 Loss: 0.0015584415197372437 ( 2.381653757765889e-06 x 1000.0 + -0.0008232122659683227 ) AUROC: 0.6778947368421053\n",
      "Epoch: 57 Loss: 0.0014589376449584961 ( 2.3415947798639537e-06 x 1000.0 + -0.0008826570510864258 ) AUROC: 0.9631578947368421\n",
      "Epoch: 58 Loss: 0.0014835638999938965 ( 2.308451570570469e-06 x 1000.0 + -0.000824887752532959 ) AUROC: 0.608421052631579\n",
      "Epoch: 59 Loss: 0.001371009111404419 ( 2.2547745611518624e-06 x 1000.0 + -0.0008837655186653137 ) AUROC: 0.9736842105263157\n",
      "Epoch: 60 Loss: 0.001207428216934204 ( 2.0902699325233697e-06 x 1000.0 + -0.0008828418254852295 ) AUROC: 0.9263157894736842\n",
      "Epoch: 61 Loss: 0.0012458634376525878 ( 2.1022481378167867e-06 x 1000.0 + -0.0008563847541809082 ) AUROC: 0.8957894736842106\n",
      "Epoch: 62 Loss: 0.001224116325378418 ( 2.063978463411331e-06 x 1000.0 + -0.0008398621678352356 ) AUROC: 0.8178947368421052\n",
      "Epoch: 63 Loss: 0.0012035481929779052 ( 2.050663577392697e-06 x 1000.0 + -0.0008471153378486633 ) AUROC: 0.8147368421052632\n",
      "Epoch: 64 Loss: 0.001254266619682312 ( 2.13673897087574e-06 x 1000.0 + -0.0008824723958969116 ) AUROC: 0.9378947368421053\n",
      "Epoch: 65 Loss: 0.0011346700191497802 ( 2.0058441441506147e-06 x 1000.0 + -0.000871174156665802 ) AUROC: 0.8421052631578947\n",
      "Epoch: 66 Loss: 0.0013063733577728272 ( 2.173409564420581e-06 x 1000.0 + -0.0008670361638069153 ) AUROC: 0.8526315789473684\n",
      "Epoch: 67 Loss: 0.0015775938034057618 ( 2.430889988318086e-06 x 1000.0 + -0.0008532962203025818 ) AUROC: 0.9347368421052632\n",
      "Epoch: 68 Loss: 0.0011654958724975587 ( 1.9882973283529283e-06 x 1000.0 + -0.0008228014111518859 ) AUROC: 0.7578947368421053\n",
      "Epoch: 69 Loss: 0.0011876633167266846 ( 2.054206794127822e-06 x 1000.0 + -0.0008665435314178467 ) AUROC: 0.9284210526315788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 Loss: 0.001038193941116333 ( 1.8922961317002774e-06 x 1000.0 + -0.0008541021347045899 ) AUROC: 0.7694736842105263\n",
      "Epoch: 71 Loss: 0.0010958502292633056 ( 1.9794292747974397e-06 x 1000.0 + -0.0008835789561271668 ) AUROC: 0.9178947368421053\n",
      "Epoch: 72 Loss: 0.0010592107772827149 ( 1.9000484608113765e-06 x 1000.0 + -0.0008408377766609192 ) AUROC: 0.8178947368421052\n",
      "Epoch: 73 Loss: 0.0010719246864318848 ( 1.959417946636677e-06 x 1000.0 + -0.0008874932527542114 ) AUROC: 0.9326315789473685\n",
      "Epoch: 74 Loss: 0.0010790703296661376 ( 1.9499320769682527e-06 x 1000.0 + -0.0008708617687225342 ) AUROC: 0.8389473684210527\n",
      "Epoch: 75 Loss: 0.0010121195316314697 ( 1.868755673058331e-06 x 1000.0 + -0.0008566362261772155 ) AUROC: 0.9157894736842105\n",
      "Epoch: 76 Loss: 0.0010500468015670777 ( 1.84722279664129e-06 x 1000.0 + -0.0007971760034561157 ) AUROC: 0.6189473684210527\n",
      "Epoch: 77 Loss: 0.0008812465071678161 ( 1.7474241321906447e-06 x 1000.0 + -0.0008661776185035706 ) AUROC: 0.9147368421052631\n",
      "Epoch: 78 Loss: 0.0009758318662643433 ( 1.7747301608324052e-06 x 1000.0 + -0.0007988983392715455 ) AUROC: 0.5789473684210527\n",
      "Epoch: 79 Loss: 0.0007866458892822265 ( 1.672852085903287e-06 x 1000.0 + -0.0008862061500549316 ) AUROC: 0.9073684210526316\n",
      "Epoch: 80 Loss: 0.0007975029349327088 ( 1.6870410181581974e-06 x 1000.0 + -0.0008895381093025207 ) AUROC: 0.9568421052631579\n",
      "Epoch: 81 Loss: 0.0009026556015014649 ( 1.753301708959043e-06 x 1000.0 + -0.0008506461381912232 ) AUROC: 0.6684210526315789\n",
      "Epoch: 82 Loss: 0.0007058143615722656 ( 1.5804145950824022e-06 x 1000.0 + -0.0008746002912521362 ) AUROC: 0.8326315789473684\n",
      "Epoch: 83 Loss: 0.0008215139508247376 ( 1.6274974914267659e-06 x 1000.0 + -0.0008059834837913513 ) AUROC: 0.5242105263157895\n",
      "Epoch: 84 Loss: 0.0006773459911346435 ( 1.564260688610375e-06 x 1000.0 + -0.0008869147300720214 ) AUROC: 0.9326315789473685\n",
      "Epoch: 85 Loss: 0.0008066514730453491 ( 1.6461934428662061e-06 x 1000.0 + -0.0008395419120788574 ) AUROC: 0.5957894736842105\n",
      "Epoch: 86 Loss: 0.0008877447247505188 ( 1.713033765554428e-06 x 1000.0 + -0.0008252890706062317 ) AUROC: 0.8778947368421053\n",
      "Epoch: 87 Loss: 0.0007085293531417846 ( 1.5936538111418485e-06 x 1000.0 + -0.0008851244449615479 ) AUROC: 0.9284210526315789\n",
      "Epoch: 88 Loss: 0.0008453001976013183 ( 1.7210001824423671e-06 x 1000.0 + -0.0008756999969482422 ) AUROC: 0.8694736842105264\n",
      "Epoch: 89 Loss: 0.0006368629932403565 ( 1.499455189332366e-06 x 1000.0 + -0.0008625922203063965 ) AUROC: 0.7494736842105263\n",
      "Epoch: 90 Loss: 0.000571885883808136 ( 1.4547195751219988e-06 x 1000.0 + -0.0008828336596488953 ) AUROC: 0.9105263157894736\n",
      "Epoch: 91 Loss: 0.0006685646772384644 ( 1.5011553186923264e-06 x 1000.0 + -0.0008325906991958618 ) AUROC: 0.7978947368421052\n",
      "Epoch: 92 Loss: 0.0006737555861473084 ( 1.5603220090270043e-06 x 1000.0 + -0.0008865664601325989 ) AUROC: 0.9452631578947368\n",
      "Epoch: 93 Loss: 0.0008075599670410156 ( 1.6866395017132163e-06 x 1000.0 + -0.0008790795803070068 ) AUROC: 0.9663157894736842\n",
      "Epoch: 94 Loss: 0.0007896822094917297 ( 1.6594247426837683e-06 x 1000.0 + -0.0008697425723075867 ) AUROC: 0.9715789473684211\n",
      "Epoch: 95 Loss: 0.0006729893684387208 ( 1.5055021503940226e-06 x 1000.0 + -0.0008325127363204956 ) AUROC: 0.7778947368421053\n",
      "Epoch: 96 Loss: 0.0005785242915153503 ( 1.4672699617221952e-06 x 1000.0 + -0.0008887457251548767 ) AUROC: 0.9621052631578948\n",
      "Epoch: 97 Loss: 0.000524555504322052 ( 1.4118594117462636e-06 x 1000.0 + -0.00088730388879776 ) AUROC: 0.9789473684210526\n",
      "Epoch: 98 Loss: 0.0004513455629348755 ( 1.3407116057351232e-06 x 1000.0 + -0.0008893660306930542 ) AUROC: 0.9547368421052631\n",
      "Epoch: 99 Loss: 0.00042383748292922974 ( 1.2695668265223502e-06 x 1000.0 + -0.0008457292914390564 ) AUROC: 0.6705263157894736\n",
      "Epoch: 100 Loss: 0.00037171804904937746 ( 1.2607000535354018e-06 x 1000.0 + -0.0008889820575714111 ) AUROC: 0.9757894736842105\n",
      "SVM train\n",
      "Train time: 10.289093255996704\n",
      "Test time: 0.006015777587890625\n",
      "{'AUPRC': 0.9981052631578947,\n",
      " 'AUROC': 0.9810526315789474,\n",
      " 'Confusion matrix': array([[457,  18],\n",
      "       [  0,  25]], dtype=int64),\n",
      " 'F1': 0.9806866952789699,\n",
      " 'P@10': 0.9591836734693877,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.9621052631578947}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Autoencoder-OneclassSVM\n",
    "    t0 = time.time()\n",
    "    ae1svm.fit_svm(sess, x_train, x_train, y_train, epochs_1=100, epochs_2=0)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    out_y = ae1svm.predict(sess, x_test)\n",
    "    print('Test time:', time.time() - t0)\n",
    "    pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder train\n",
      "Epoch: 1 Loss: 0.00010470106452703476\n",
      "Epoch: 2 Loss: 5.381616204977035e-05\n",
      "Epoch: 3 Loss: 2.908489853143692e-05\n",
      "Epoch: 4 Loss: 2.4308552965521813e-05\n",
      "Epoch: 5 Loss: 2.0358726382255554e-05\n",
      "Epoch: 6 Loss: 1.6976684331893922e-05\n",
      "Epoch: 7 Loss: 1.454909611493349e-05\n",
      "Epoch: 8 Loss: 1.1869112960994243e-05\n",
      "Epoch: 9 Loss: 1.0397476144134998e-05\n",
      "Epoch: 10 Loss: 9.539371356368065e-06\n",
      "Epoch: 11 Loss: 8.81444290280342e-06\n",
      "Epoch: 12 Loss: 8.34535900503397e-06\n",
      "Epoch: 13 Loss: 8.289985358715057e-06\n",
      "Epoch: 14 Loss: 7.725147996097803e-06\n",
      "Epoch: 15 Loss: 7.5929155573248864e-06\n",
      "Epoch: 16 Loss: 7.307859603315592e-06\n",
      "Epoch: 17 Loss: 6.666031666100025e-06\n",
      "Epoch: 18 Loss: 6.457554176449776e-06\n",
      "Epoch: 19 Loss: 5.873235873878002e-06\n",
      "Epoch: 20 Loss: 5.615349858999252e-06\n",
      "Epoch: 21 Loss: 5.377361085265875e-06\n",
      "Epoch: 22 Loss: 5.271044559776783e-06\n",
      "Epoch: 23 Loss: 4.9993726424872875e-06\n",
      "Epoch: 24 Loss: 5.024246871471405e-06\n",
      "Epoch: 25 Loss: 4.674649331718683e-06\n",
      "Epoch: 26 Loss: 4.39245393499732e-06\n",
      "Epoch: 27 Loss: 4.220536444336176e-06\n",
      "Epoch: 28 Loss: 4.158542025834322e-06\n",
      "Epoch: 29 Loss: 3.999236971139908e-06\n",
      "Epoch: 30 Loss: 3.8709451910108325e-06\n",
      "Epoch: 31 Loss: 3.9588995277881625e-06\n",
      "Epoch: 32 Loss: 3.882694523781538e-06\n",
      "Epoch: 33 Loss: 3.793974407017231e-06\n",
      "Epoch: 34 Loss: 3.826259169727564e-06\n",
      "Epoch: 35 Loss: 3.8048357237130405e-06\n",
      "Epoch: 36 Loss: 3.658558940514922e-06\n",
      "Epoch: 37 Loss: 3.3781845122575758e-06\n",
      "Epoch: 38 Loss: 3.442289773374796e-06\n",
      "Epoch: 39 Loss: 3.196200355887413e-06\n",
      "Epoch: 40 Loss: 3.241725033149123e-06\n",
      "Epoch: 41 Loss: 3.427902702242136e-06\n",
      "Epoch: 42 Loss: 3.3667462412267925e-06\n",
      "Epoch: 43 Loss: 3.189521376043558e-06\n",
      "Epoch: 44 Loss: 3.125803079456091e-06\n",
      "Epoch: 45 Loss: 3.0552879907190798e-06\n",
      "Epoch: 46 Loss: 2.8602241072803735e-06\n",
      "Epoch: 47 Loss: 2.911795163527131e-06\n",
      "Epoch: 48 Loss: 2.7071789372712376e-06\n",
      "Epoch: 49 Loss: 2.629933413118124e-06\n",
      "Epoch: 50 Loss: 2.540834015235305e-06\n",
      "Epoch: 51 Loss: 2.5874576531350613e-06\n",
      "Epoch: 52 Loss: 2.720818622037768e-06\n",
      "Epoch: 53 Loss: 2.703180070966482e-06\n",
      "Epoch: 54 Loss: 2.911861054599285e-06\n",
      "Epoch: 55 Loss: 2.7382420375943184e-06\n",
      "Epoch: 56 Loss: 2.588119590654969e-06\n",
      "Epoch: 57 Loss: 2.350187860429287e-06\n",
      "Epoch: 58 Loss: 2.4846745654940604e-06\n",
      "Epoch: 59 Loss: 2.3283003829419613e-06\n",
      "Epoch: 60 Loss: 2.4157578591257335e-06\n",
      "Epoch: 61 Loss: 2.4141683243215083e-06\n",
      "Epoch: 62 Loss: 2.410956425592303e-06\n",
      "Epoch: 63 Loss: 2.171210711821914e-06\n",
      "Epoch: 64 Loss: 2.0619225688278674e-06\n",
      "Epoch: 65 Loss: 2.0282783079892395e-06\n",
      "Epoch: 66 Loss: 1.9531454890966415e-06\n",
      "Epoch: 67 Loss: 1.9012319389730693e-06\n",
      "Epoch: 68 Loss: 1.8225695239380003e-06\n",
      "Epoch: 69 Loss: 1.917222747579217e-06\n",
      "Epoch: 70 Loss: 1.822342979721725e-06\n",
      "Epoch: 71 Loss: 1.934130908921361e-06\n",
      "Epoch: 72 Loss: 1.990884309634566e-06\n",
      "Epoch: 73 Loss: 1.7087500309571623e-06\n",
      "Epoch: 74 Loss: 1.7582663567736745e-06\n",
      "Epoch: 75 Loss: 1.8301689997315406e-06\n",
      "Epoch: 76 Loss: 1.6801398014649748e-06\n",
      "Epoch: 77 Loss: 1.6501609934493899e-06\n",
      "Epoch: 78 Loss: 1.8449422204867006e-06\n",
      "Epoch: 79 Loss: 1.654413645155728e-06\n",
      "Epoch: 80 Loss: 1.632479950785637e-06\n",
      "Epoch: 81 Loss: 1.7560390988364816e-06\n",
      "Epoch: 82 Loss: 1.6184506239369512e-06\n",
      "Epoch: 83 Loss: 1.610554987564683e-06\n",
      "Epoch: 84 Loss: 1.6835866263136267e-06\n",
      "Epoch: 85 Loss: 1.6192600596696138e-06\n",
      "Epoch: 86 Loss: 1.5829120529815556e-06\n",
      "Epoch: 87 Loss: 1.7107171006500721e-06\n",
      "Epoch: 88 Loss: 1.6465312801301479e-06\n",
      "Epoch: 89 Loss: 1.7300317995250226e-06\n",
      "Epoch: 90 Loss: 1.4728624373674392e-06\n",
      "Epoch: 91 Loss: 1.3487620744854212e-06\n",
      "Epoch: 92 Loss: 1.597318914718926e-06\n",
      "Epoch: 93 Loss: 1.4880631351843476e-06\n",
      "Epoch: 94 Loss: 1.3680958654731511e-06\n",
      "Epoch: 95 Loss: 1.2365777511149644e-06\n",
      "Epoch: 96 Loss: 1.282896613702178e-06\n",
      "Epoch: 97 Loss: 1.200714730657637e-06\n",
      "Epoch: 98 Loss: 1.2664794921875e-06\n",
      "Epoch: 99 Loss: 1.3168068835511803e-06\n",
      "Epoch: 100 Loss: 1.2241153744980693e-06\n",
      "AE time: 8.257127046585083\n"
     ]
    }
   ],
   "source": [
    "ae_only = AEOneClassSVM(data_input, batch_size, 'test_ae', autoencoder_layers[1:], 0.28, 1e3, 3.0, 500,\n",
    "                       autoencoder_activation='sigmoid',\n",
    "                       ae_op=tf.train.AdamOptimizer(5e-3))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Train autoencoder for conventional methods\n",
    "    t0 = time.time()\n",
    "    ae_only.fit_ae(sess, x_train, epochs=100)\n",
    "    print('AE time:', time.time() - t0)\n",
    "\n",
    "    x_train_encoded = ae_only.encode(sess, x_train)\n",
    "    x_test_encoded = ae_only.encode(sess, x_test)\n",
    "\n",
    "    x_train_rff = ae_only.encode_rff(sess, x_train)\n",
    "    x_test_rff = ae_only.encode_rff(sess, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 0.008021116256713867\n",
      "Test time: 0.0030083656311035156\n",
      "{'AUPRC': 0.9976842105263158,\n",
      " 'AUROC': 0.976842105263158,\n",
      " 'Confusion matrix': array([[453,  22],\n",
      "       [  0,  25]], dtype=int64),\n",
      " 'F1': 0.9762931034482758,\n",
      " 'P@10': 0.9612244897959183,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.9536842105263158}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional OCSVM on \n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.12, verbose=True, shrinking=False)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_encoded)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_encoded)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-Linear\n",
      "[LibSVM]Train time: 0.021056413650512695\n",
      "Test time: 0.0030105113983154297\n",
      "{'AUPRC': 0.985731343283582,\n",
      " 'AUROC': 0.86,\n",
      " 'Confusion matrix': array([[399,  76],\n",
      "       [  3,  22]], dtype=int64),\n",
      " 'F1': 0.9099201824401367,\n",
      " 'P@10': 0.9530612244897959,\n",
      " 'Precision': 0.9925373134328358,\n",
      " 'Recall': 0.84}\n"
     ]
    }
   ],
   "source": [
    "print('OCSVM-Linear')\n",
    "libsvm = OneClassSVM(nu=0.22, verbose=True, shrinking=False, kernel='linear')\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_encoded)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_encoded)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-Linear on RFF\n",
      "[LibSVM]Train time: 0.08923578262329102\n",
      "Test time: 0.05213737487792969\n",
      "{'AUPRC': 0.9977894736842106,\n",
      " 'AUROC': 0.9778947368421053,\n",
      " 'Confusion matrix': array([[454,  21],\n",
      "       [  0,  25]], dtype=int64),\n",
      " 'F1': 0.9773950484391819,\n",
      " 'P@10': 0.9591836734693877,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.9557894736842105}\n"
     ]
    }
   ],
   "source": [
    "print('OCSVM-Linear on RFF')\n",
    "libsvm = OneClassSVM(nu=0.115, verbose=True, shrinking=True, kernel='linear')\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_rff)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_rff)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
