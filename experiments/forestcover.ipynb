{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nghia\\PycharmProjects\\ECML\\Refactor\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nghia\\anaconda2\\envs\\tf36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from load_datasets import forestcover\n",
    "from metrics import metrics\n",
    "from models.AE1SVM import AEOneClassSVM\n",
    "from models.DEC import DEC\n",
    "from models.RDA import RobustL21Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies ratio: 0.959985456884557 %\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(2018)\n",
    "\n",
    "x_train, y_train, x_test, y_test = forestcover(random_state=1)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('Anomalies ratio:', 100*counter[-1]/(counter[1]+counter[-1]), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 667.1862211227417\n",
      "Test time: 206.36981987953186\n",
      "{'AUPRC': 0.06440725636338068,\n",
      " 'AUROC': 0.9295486795010272,\n",
      " 'Confusion matrix': array([[  1374,      0],\n",
      "       [ 19959, 121692]], dtype=int64),\n",
      " 'F1': 0.12101994979521735,\n",
      " 'Precision': 0.06440725636338068,\n",
      " 'Recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Train OC-SVM on raw input\n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.15, verbose=True, shrinking=False)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 26.88950824737549\n",
      "Test time: 10.3134286403656\n",
      "{'AUPRC': 0.07791594252340163,\n",
      " 'AUROC': 0.9377957230451286,\n",
      " 'Confusion matrix': array([[  1357,     17],\n",
      "       [ 15870, 125781]], dtype=int64),\n",
      " 'F1': 0.14590613407881298,\n",
      " 'Precision': 0.0787716955941255,\n",
      " 'Recall': 0.987627365356623}\n"
     ]
    }
   ],
   "source": [
    "# Train Isolation Forest\n",
    "print('IsolationForest')\n",
    "iforest = IsolationForest(contamination=0.12, verbose=1)\n",
    "t0 = time.time()\n",
    "iforest.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = iforest.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_layers = [54, 32, 16]\n",
    "batch_size = 1024\n",
    "\n",
    "nu = 0.3\n",
    "alpha = 1e3\n",
    "sigma = 3.0\n",
    "kernel_features = 200\n",
    "\n",
    "data_input = tf.placeholder(tf.float32, shape=[None, 54])\n",
    "\n",
    "ae1svm = AEOneClassSVM(data_input, batch_size, 'ae1svm', autoencoder_layers[1:], nu, alpha, sigma, kernel_features,\n",
    "                       autoencoder_activation='sigmoid', seed=4,\n",
    "                       full_op=tf.train.AdamOptimizer(1e-2),\n",
    "                       svm_op=tf.train.AdamOptimizer(1e-4))\n",
    "\n",
    "ae_only = AEOneClassSVM(data_input, batch_size, 'ae_only', autoencoder_layers[1:], nu, alpha, sigma, kernel_features,\n",
    "                        autoencoder_activation='sigmoid', ae_op=tf.train.AdamOptimizer(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train\n",
      ".......SVM train\n",
      "Train time: 17.757224321365356\n",
      "Test time: 0.7118942737579346\n",
      "{'AUPRC': 0.1575109070898659,\n",
      " 'AUROC': 0.9519615665280303,\n",
      " 'Confusion matrix': array([[  1306,     68],\n",
      "       [  6599, 135052]], dtype=int64),\n",
      " 'F1': 0.2814958508459964,\n",
      " 'Precision': 0.16521189120809615,\n",
      " 'Recall': 0.950509461426492}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Autoencoder-OneclassSVM\n",
    "    t0 = time.time()\n",
    "    ae1svm.fit(sess, x_train, epochs_1=7, epochs_2=0)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    out_y = ae1svm.predict(sess, x_test)\n",
    "    print('Test time:', time.time() - t0)\n",
    "\n",
    "    pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_only = AEOneClassSVM(data_input, batch_size, 'ae_only', autoencoder_layers[1:], nu, alpha, sigma, kernel_features,\n",
    "                        autoencoder_activation='sigmoid', ae_op=tf.train.AdamOptimizer(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder train\n",
      "....................AE time: 13.412670612335205\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Train autoencoder for conventional methods\n",
    "    t0 = time.time()\n",
    "    ae_only.fit_ae(sess, x_train, epochs=20)\n",
    "    print('AE time:', time.time() - t0)\n",
    "\n",
    "    x_train_encoded = ae_only.encode(sess, x_train)\n",
    "    x_test_encoded = ae_only.encode(sess, x_test)\n",
    "\n",
    "    x_train_rff = ae_only.encode_rff(sess, x_train)\n",
    "    x_test_rff = ae_only.encode_rff(sess, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 377.64098834991455\n",
      "Test time: 130.73426866531372\n",
      "{'AUPRC': 0.02291982735476698,\n",
      " 'AUROC': 0.6948486299080782,\n",
      " 'Confusion matrix': array([[   735,    639],\n",
      "       [ 20573, 121078]], dtype=int64),\n",
      " 'F1': 0.0648090997266555,\n",
      " 'Precision': 0.03449408672798949,\n",
      " 'Recall': 0.5349344978165939}\n"
     ]
    }
   ],
   "source": [
    "# Train OCSVM on encoded \n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.15, verbose=True, shrinking=False)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_encoded)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_encoded)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-Linear on RFF\n",
      "[LibSVM]Train time: 8277.284163236618\n",
      "Test time: 1586.538587808609\n",
      "{'AUPRC': 0.02459405814671357,\n",
      " 'AUROC': 0.7079519335901489,\n",
      " 'Confusion matrix': array([[   769,    605],\n",
      "       [ 20366, 121285]], dtype=int64),\n",
      " 'F1': 0.06832822426584922,\n",
      " 'Precision': 0.036385143127513606,\n",
      " 'Recall': 0.5596797671033479}\n"
     ]
    }
   ],
   "source": [
    "print('OCSVM-Linear on RFF')\n",
    "libsvm = OneClassSVM(nu=0.15, verbose=True, shrinking=False, kernel='linear', tol=0.1)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_rff)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_rff)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Pretraining...\n",
      "Epoch 1/5\n",
      "143023/143023 [==============================] - 2s 14us/step - loss: 0.0149\n",
      "Epoch 2/5\n",
      "143023/143023 [==============================] - 1s 9us/step - loss: 0.0035\n",
      "Epoch 3/5\n",
      "143023/143023 [==============================] - 1s 9us/step - loss: 0.0023\n",
      "Epoch 4/5\n",
      "143023/143023 [==============================] - 1s 10us/step - loss: 0.0017\n",
      "Epoch 5/5\n",
      "143023/143023 [==============================] - 1s 9us/step - loss: 0.0015\n",
      "Pretraining time:  7.523931503295898\n",
      "Update interval 10\n",
      "Save interval 698.3544921875\n",
      "Initializing cluster centers with k-means.\n",
      "delta_label  0.0 < tol  0.001\n",
      "Reached tolerance threshold. Stopping training.\n",
      "Train time: 20.789042234420776\n",
      "Test time: 3.1183419227600098\n",
      "{'AUPRC': 0.030755040442172407,\n",
      " 'AUROC': 0.8441889006435923,\n",
      " 'Confusion matrix': array([[ 1357,    17],\n",
      "       [42389, 99262]], dtype=int64),\n",
      " 'F1': 0.06015070921985816,\n",
      " 'Precision': 0.031019978969505785,\n",
      " 'Recall': 0.987627365356623}\n"
     ]
    }
   ],
   "source": [
    "dec = DEC(dims=autoencoder_layers, n_clusters=5)\n",
    "t0 = time.time()\n",
    "dec.pretrain(x=x_train, epochs=5)\n",
    "dec.compile(loss='kld')\n",
    "y_pred = dec.fit(x_train, update_interval=10, batch_size=batch_size)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "scores = dec.cluster_score(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "threshold = np.partition(scores.flatten(), int(counter[-1]))[int(counter[-1])]\n",
    "out_y = np.array([1 if s > 3*threshold else -1 for s in scores])\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (143023, 54)\n",
      "L shape:  (143023, 54)\n",
      "S shape:  (143023, 54)\n",
      "Out iteration:  1\n",
      "    iteration :  5 , cost :  0.012954294\n",
      "    iteration :  10 , cost :  0.005389897\n",
      "    iteration :  15 , cost :  0.0034266175\n",
      "    iteration :  20 , cost :  0.0025623078\n",
      "    iteration :  25 , cost :  0.0018427641\n",
      "    iteration :  30 , cost :  0.0013280164\n",
      "    iteration :  35 , cost :  0.0010048331\n",
      "    iteration :  40 , cost :  0.00075372943\n",
      "    iteration :  45 , cost :  0.0006544672\n",
      "    iteration :  50 , cost :  0.0005267294\n",
      "Out iteration:  2\n",
      "    iteration :  5 , cost :  0.0001509908\n",
      "    iteration :  10 , cost :  0.00013877971\n",
      "    iteration :  15 , cost :  0.00012848702\n",
      "    iteration :  20 , cost :  0.00011636284\n",
      "    iteration :  25 , cost :  0.00010890679\n",
      "    iteration :  30 , cost :  0.000102827\n",
      "    iteration :  35 , cost :  9.7523414e-05\n",
      "    iteration :  40 , cost :  9.3104274e-05\n",
      "    iteration :  45 , cost :  8.9624824e-05\n",
      "    iteration :  50 , cost :  8.6396496e-05\n",
      "Out iteration:  3\n",
      "    iteration :  5 , cost :  9.0378e-05\n",
      "    iteration :  10 , cost :  8.664971e-05\n",
      "    iteration :  15 , cost :  8.411159e-05\n",
      "    iteration :  20 , cost :  8.206778e-05\n",
      "    iteration :  25 , cost :  8.0404905e-05\n",
      "    iteration :  30 , cost :  7.8857396e-05\n",
      "    iteration :  35 , cost :  7.753723e-05\n",
      "    iteration :  40 , cost :  7.6397504e-05\n",
      "    iteration :  45 , cost :  7.5283264e-05\n",
      "    iteration :  50 , cost :  7.48245e-05\n",
      "Train time: 106.0590877532959\n",
      "Test time: 1.4354252815246582\n",
      "{'AUPRC': 0.06012281746766411,\n",
      " 'AUROC': 0.9184613398345814,\n",
      " 'Confusion matrix': array([[  1352,     22],\n",
      "       [ 20832, 120819]], dtype=int64),\n",
      " 'F1': 0.11478054164190508,\n",
      " 'Precision': 0.060944825099170576,\n",
      " 'Recall': 0.9839883551673945}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Robust Deep Autoencoder\n",
    "    rae = RobustL21Autoencoder(sess=sess, lambda_=0.1, layers_sizes=autoencoder_layers, learning_rate=1e-2)\n",
    "    t0 = time.time()\n",
    "    L, S = rae.fit(x_train, sess=sess, inner_iteration=50, iteration=3, verbose=True, batch_size=batch_size)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    L_test, S_test = rae.predict(x_test, sess=sess)\n",
    "    print('Test time:', time.time() - t0)\n",
    "\n",
    "    s_sum = np.linalg.norm(S, axis=1)\n",
    "    s_sum_test = np.linalg.norm(S_test, axis=1)\n",
    "    out_y = np.array([1 if s == 0 else -1 for s in s_sum_test])\n",
    "    pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
