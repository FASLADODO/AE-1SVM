{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nghia\\PycharmProjects\\ECML\\Refactor\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from load_datasets import forestcover\n",
    "from metrics import metrics\n",
    "from models.AE1SVM import AEOneClassSVM\n",
    "from models.DEC import DEC\n",
    "from models.RDA import RobustL21Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies ratio: 0.959985456884557 %\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(2018)\n",
    "\n",
    "x_train, y_train, x_test, y_test = forestcover(random_state=1)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('Anomalies ratio:', 100*counter[-1]/(counter[1]+counter[-1]), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 650.0681240558624\n",
      "Test time: 204.22370100021362\n",
      "{'AUPRC': 0.9986463888919337,\n",
      " 'AUROC': 0.9295486795010272,\n",
      " 'Confusion matrix': array([[121692,  19959],\n",
      "       [     0,   1374]], dtype=int64),\n",
      " 'F1': 0.9242091113111037,\n",
      " 'P@10': 0.9903926161591442,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.8590973590020543}\n",
      "OCSVM-Linear\n",
      "[LibSVM]Train time: 438.180704832077\n",
      "Test time: 145.50284790992737\n",
      "{'AUPRC': 0.998651814458778,\n",
      " 'AUROC': 0.9298310636705707,\n",
      " 'Confusion matrix': array([[121772,  19879],\n",
      "       [     0,   1374]], dtype=int64),\n",
      " 'F1': 0.9245358226123003,\n",
      " 'P@10': 0.9903996084326819,\n",
      " 'Precision': 1.0,\n",
      " 'Recall': 0.8596621273411412}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional RBF-OCSVM on raw input\n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.15, verbose=True, shrinking=False)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))\n",
    "\n",
    "# Train conventional Linear-OCSVM\n",
    "print('OCSVM-Linear')\n",
    "libsvm = OneClassSVM(nu=0.15, verbose=True, shrinking=False, kernel='linear')\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 27.721354484558105\n",
      "Test time: 10.483874082565308\n",
      "{'AUPRC': 0.9988391944940953,\n",
      " 'AUROC': 0.9396290159475843,\n",
      " 'Confusion matrix': array([[125888,  15763],\n",
      "       [    13,   1361]], dtype=int64),\n",
      " 'F1': 0.941035761272575,\n",
      " 'P@10': 0.9904066007062197,\n",
      " 'Precision': 0.9998967442673211,\n",
      " 'Recall': 0.8887194583871628}\n"
     ]
    }
   ],
   "source": [
    "# Train Isolation Forest\n",
    "print('IsolationForest')\n",
    "iforest = IsolationForest(contamination=0.12, verbose=1)\n",
    "t0 = time.time()\n",
    "iforest.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = iforest.predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF\n",
      "Train time: 593.2050950527191\n",
      "Test time: 583.6405622959137\n",
      "{'AUPRC': 0.991153879730001,\n",
      " 'AUROC': 0.539934131117937,\n",
      " 'Confusion matrix': array([[119562,  22089],\n",
      "       [  1050,    324]], dtype=int64),\n",
      " 'F1': 0.9117717710847507,\n",
      " 'P@10': 0.9903926161591442,\n",
      " 'Precision': 0.9912943985673067,\n",
      " 'Recall': 0.8440604019738653}\n"
     ]
    }
   ],
   "source": [
    "# Train Local outlier factor\n",
    "print('LOF')\n",
    "lof = LocalOutlierFactor(contamination=0.15)\n",
    "t0 = time.time()\n",
    "lof.fit(x_train)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = lof._predict(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_layers = [54, 32, 16]\n",
    "batch_size = 1024\n",
    "\n",
    "nu = 0.3\n",
    "alpha = 1e3\n",
    "sigma = 3.0\n",
    "kernel_features = 200\n",
    "\n",
    "data_input = tf.placeholder(tf.float32, shape=[None, 54])\n",
    "\n",
    "ae1svm = AEOneClassSVM(data_input, batch_size, 'ae1svm', autoencoder_layers[1:], nu, alpha, sigma, kernel_features,\n",
    "                       autoencoder_activation='sigmoid',\n",
    "                       full_op=tf.train.AdamOptimizer(1e-2),\n",
    "                       svm_op=tf.train.AdamOptimizer(1e-4))\n",
    "\n",
    "ae_only = AEOneClassSVM(data_input, batch_size, 'ae_only', autoencoder_layers[1:], nu, alpha, sigma, kernel_features,\n",
    "                        autoencoder_activation='sigmoid', ae_op=tf.train.AdamOptimizer(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train\n",
      "Epoch: 1 Loss: 0.00014666299147880716 ( 9.464924214897677e-08 x 1000.0 + 5.201374781911648e-05 ) AUROC: 0.4400035298270385\n",
      "Epoch: 2 Loss: 4.721038601890115e-05 ( 4.8324804854829927e-08 x 1000.0 + -1.1144178201038983e-06 ) AUROC: 0.38412989763501587\n",
      "Epoch: 3 Loss: 3.182055450516482e-05 ( 3.4719712484064854e-08 x 1000.0 + -2.8991558691099076e-06 ) AUROC: 0.4556084349754699\n",
      "Epoch: 4 Loss: 2.601387028620038e-05 ( 2.8948303435186403e-08 x 1000.0 + -2.934431768506056e-06 ) AUROC: 0.39005935148362003\n",
      "Epoch: 5 Loss: 1.8599943151395517e-05 ( 2.1493998147040324e-08 x 1000.0 + -2.894053615164842e-06 ) AUROC: 0.9459266053064639\n",
      "SVM train\n",
      "Train time: 17.82639503479004\n",
      "Test time: 0.7299408912658691\n",
      "{'AUPRC': 0.9990065686193581,\n",
      " 'AUROC': 0.9485999694988103,\n",
      " 'Confusion matrix': array([[136677,   4974],\n",
      "       [    93,   1281]], dtype=int64),\n",
      " 'F1': 0.9818009417393084,\n",
      " 'P@10': 0.9903926161591442,\n",
      " 'Precision': 0.9993200263215617,\n",
      " 'Recall': 0.9648855285172713}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Autoencoder-OneclassSVM\n",
    "    t0 = time.time()\n",
    "    ae1svm.fit(sess, x_train, x_train, y_train, epochs_1=5, epochs_2=0)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    out_y = ae1svm.predict(sess, x_test)\n",
    "    print('Test time:', time.time() - t0)\n",
    "\n",
    "    pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder train\n",
      "Epoch: 1 Loss: 1.1125966544705516e-07\n",
      "Epoch: 2 Loss: 5.911390368346313e-08\n",
      "Epoch: 3 Loss: 3.6418744710830276e-08\n",
      "Epoch: 4 Loss: 2.5531345290079753e-08\n",
      "Epoch: 5 Loss: 1.9358984952182237e-08\n",
      "Epoch: 6 Loss: 1.6344433460584465e-08\n",
      "Epoch: 7 Loss: 1.4588433644382216e-08\n",
      "Epoch: 8 Loss: 1.3104460009665194e-08\n",
      "Epoch: 9 Loss: 1.192884945886866e-08\n",
      "Epoch: 10 Loss: 1.056525351417567e-08\n",
      "Epoch: 11 Loss: 9.617295993207667e-09\n",
      "Epoch: 12 Loss: 8.761474928293586e-09\n",
      "Epoch: 13 Loss: 8.368218024354054e-09\n",
      "Epoch: 14 Loss: 7.783030451528069e-09\n",
      "Epoch: 15 Loss: 7.4201359671629306e-09\n",
      "Epoch: 16 Loss: 7.190415473238131e-09\n",
      "Epoch: 17 Loss: 6.942554202811951e-09\n",
      "Epoch: 18 Loss: 6.426770341546737e-09\n",
      "Epoch: 19 Loss: 6.25005913867288e-09\n",
      "Epoch: 20 Loss: 6.119288778735013e-09\n",
      "AE time: 18.138222455978394\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Train autoencoder for conventional methods\n",
    "    t0 = time.time()\n",
    "    ae_only.fit_ae(sess, x_train, epochs=20)\n",
    "    print('AE time:', time.time() - t0)\n",
    "\n",
    "    x_train_encoded = ae_only.encode(sess, x_train)\n",
    "    x_test_encoded = ae_only.encode(sess, x_test)\n",
    "\n",
    "    x_train_rff = ae_only.encode_rff(sess, x_train)\n",
    "    x_test_rff = ae_only.encode_rff(sess, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-RBF\n",
      "[LibSVM]Train time: 272.17249059677124\n",
      "Test time: 77.8259129524231\n",
      "{'AUPRC': 0.9959400134759321,\n",
      " 'AUROC': 0.7895934975064337,\n",
      " 'Confusion matrix': array([[121115,  20536],\n",
      "       [   379,    995]], dtype=int64),\n",
      " 'F1': 0.9205191054361663,\n",
      " 'P@10': 0.9903926161591442,\n",
      " 'Precision': 0.9968805043870479,\n",
      " 'Recall': 0.85502396735639}\n"
     ]
    }
   ],
   "source": [
    "# Train conventional OCSVM on \n",
    "print('OCSVM-RBF')\n",
    "libsvm = OneClassSVM(nu=0.15, verbose=True, shrinking=False)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_encoded)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_encoded)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-Linear\n",
      "[LibSVM]Train time: 165.3895058631897\n",
      "Test time: 38.25267243385315\n",
      "{'AUPRC': 0.9977500004218368,\n",
      " 'AUROC': 0.8832912238730289,\n",
      " 'Confusion matrix': array([[121577,  20074],\n",
      "       [   126,   1248]], dtype=int64),\n",
      " 'F1': 0.9232971589571453,\n",
      " 'P@10': 0.9903926161591442,\n",
      " 'Precision': 0.9989646927355941,\n",
      " 'Recall': 0.8582855045146169}\n"
     ]
    }
   ],
   "source": [
    "print('OCSVM-Linear')\n",
    "libsvm = OneClassSVM(nu=0.15, verbose=True, shrinking=False, kernel='linear')\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_encoded)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_encoded)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM-Linear on RFF\n",
      "[LibSVM]Train time: 3992.885948896408\n",
      "Test time: 1428.4482157230377\n",
      "{'AUPRC': 0.9962071651017566,\n",
      " 'AUROC': 0.8034464448403371,\n",
      " 'Confusion matrix': array([[121122,  20529],\n",
      "       [   341,   1033]], dtype=int64),\n",
      " 'F1': 0.9206807695523614,\n",
      " 'P@10': 0.9903926161591442,\n",
      " 'Precision': 0.9971925606974964,\n",
      " 'Recall': 0.8550733845860601}\n"
     ]
    }
   ],
   "source": [
    "print('OCSVM-Linear on RFF')\n",
    "libsvm = OneClassSVM(nu=0.15, verbose=True, shrinking=False, kernel='linear', tol=0.1)\n",
    "t0 = time.time()\n",
    "libsvm.fit(x_train_rff)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "out_y = libsvm.predict(x_test_rff)\n",
    "print('Test time:', time.time() - t0)\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (143023, 54)\n",
      "L shape:  (143023, 54)\n",
      "S shape:  (143023, 54)\n",
      "Out iteration:  1\n",
      "    iteration :  5 , cost :  0.012827324\n",
      "    iteration :  10 , cost :  0.0057799467\n",
      "    iteration :  15 , cost :  0.0033998762\n",
      "    iteration :  20 , cost :  0.0024248757\n",
      "    iteration :  25 , cost :  0.0018074346\n",
      "    iteration :  30 , cost :  0.0012522194\n",
      "    iteration :  35 , cost :  0.00090303144\n",
      "    iteration :  40 , cost :  0.0007304976\n",
      "    iteration :  45 , cost :  0.00053044077\n",
      "    iteration :  50 , cost :  0.00046837973\n",
      "Out iteration:  2\n",
      "    iteration :  5 , cost :  0.00015460704\n",
      "    iteration :  10 , cost :  0.00014110544\n",
      "    iteration :  15 , cost :  0.00013211335\n",
      "    iteration :  20 , cost :  0.00012469363\n",
      "    iteration :  25 , cost :  0.000118431075\n",
      "    iteration :  30 , cost :  0.00011327817\n",
      "    iteration :  35 , cost :  0.00010917027\n",
      "    iteration :  40 , cost :  0.00010583029\n",
      "    iteration :  45 , cost :  0.00010290249\n",
      "    iteration :  50 , cost :  9.987227e-05\n",
      "Out iteration:  3\n",
      "    iteration :  5 , cost :  0.00010411533\n",
      "    iteration :  10 , cost :  0.00010098866\n",
      "    iteration :  15 , cost :  9.8275465e-05\n",
      "    iteration :  20 , cost :  9.537362e-05\n",
      "    iteration :  25 , cost :  9.2695256e-05\n",
      "    iteration :  30 , cost :  9.03222e-05\n",
      "    iteration :  35 , cost :  8.8519504e-05\n",
      "    iteration :  40 , cost :  8.7228036e-05\n",
      "    iteration :  45 , cost :  8.623655e-05\n",
      "    iteration :  50 , cost :  8.510366e-05\n",
      "Train time: 111.34366655349731\n",
      "Test time: 2.05145263671875\n",
      "{'AUPRC': 0.9974653172635972,\n",
      " 'AUROC': 0.8683749583321504,\n",
      " 'Confusion matrix': array([[113846,  27805],\n",
      "       [    92,   1282]], dtype=int64),\n",
      " 'F1': 0.8908521102238358,\n",
      " 'P@10': 0.9903926161591442,\n",
      " 'Precision': 0.9991925433130299,\n",
      " 'Recall': 0.8037077041461056}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Robust Deep Autoencoder\n",
    "    rae = RobustL21Autoencoder(sess=sess, lambda_=0.1, layers_sizes=autoencoder_layers, learning_rate=1e-2)\n",
    "    t0 = time.time()\n",
    "    L, S = rae.fit(x_train, sess=sess, inner_iteration=50, iteration=3, verbose=True, batch_size=batch_size)\n",
    "    print('Train time:', time.time() - t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    L_test, S_test = rae.predict(x_test, sess=sess)\n",
    "    print('Test time:', time.time() - t0)\n",
    "\n",
    "    s_sum = np.linalg.norm(S, axis=1)\n",
    "    s_sum_test = np.linalg.norm(S_test, axis=1)\n",
    "    out_y = [1 if s == 0 else -1 for s in s_sum_test]\n",
    "    pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Pretraining...\n",
      "Pretraining time:  0.491274356842041\n",
      "Update interval 10\n",
      "Save interval 698.3544921875\n",
      "Initializing cluster centers with k-means.\n",
      "delta_label  0.0009998391867042365 < tol  0.001\n",
      "Reached tolerance threshold. Stopping training.\n",
      "Train time: 293.00256514549255\n",
      "Test time: 6.5794923305511475\n",
      "{'AUPRC': 0.9984293909982355,\n",
      " 'AUROC': 0.9184462110102142,\n",
      " 'Confusion matrix': array([[124423,  17228],\n",
      "       [    57,   1317]], dtype=int64),\n",
      " 'F1': 0.9350507832608753,\n",
      " 'P@10': 0.9903926161591442,\n",
      " 'Precision': 0.9995420951156813,\n",
      " 'Recall': 0.8783771381776337}\n"
     ]
    }
   ],
   "source": [
    "dec = DEC(dims=autoencoder_layers, n_clusters=5)\n",
    "t0 = time.time()\n",
    "dec.pretrain(x=x_train, epochs=1)\n",
    "dec.compile(loss='kld')\n",
    "y_pred = dec.fit(x_train, update_interval=10, batch_size=batch_size)\n",
    "print('Train time:', time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "scores = dec.cluster_score(x_test)\n",
    "print('Test time:', time.time() - t0)\n",
    "threshold = np.partition(scores.flatten(), int(3*counter[-1]))[int(3*counter[-1])]\n",
    "out_y = [1 if s > 2*threshold else -1 for s in scores]\n",
    "pprint(metrics(y_test, out_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
